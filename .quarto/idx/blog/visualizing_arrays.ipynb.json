{"title":"Visualizing Arrays using Excel","markdown":{"yaml":{"title":"Visualizing Arrays using Excel","execute":{"enabled":false,"freeze":true},"date":"6/23/2024","date-modified":"6/23/2024","categories":["array","numpy","tensor","excel"]},"headingText":"Element wise operation","containsRefs":false,"markdown":"\n\n\n>Visualizing simple operations across arrays\n\nIn deep learning world, we are always working with arrays and tensors. They are data structure in which we store data for our model to train on. Both are multi-dimensional data structure and have similar functionality, but tensors had more restrictions than arrays.\n\nTensor must:\n- use a single basic numerical type for all components in the array.\n- can not be jagged. It is always regularly shaped multi-dimensional rectangular structure.\n\nI always had trouble trying to understand what exactly happen when we perform operations on any data structure that has higher dimension than a list (dimension of 1). \n\nSo, let's use Excel to visualize some basic operations on arrays (or tensors)! Say we have 2 tensors, a and b. Both of dimension of 3.\n\n![image-2.png](attachment:image-2.png)\n\n\n![image-2.png](attachment:image-2.png)\n\nIf we subtract tensor a - tensor b, we are doing elementwise operation because both tensors a and b are of the same shape.\n\n\n# Sum across tensor\n\n![image.png](attachment:image.png)\n\nIf we sum across the whole tensor, we will get a scalar value (dimension 0). Scalar value is another name for *a number*.\n\n# Sum across axis\n\nNow, let's do sum operation across axis. Axis could be sample, row or column. Notice that our tensor `a_b` had shape of (2,3,4). This means it is made up of 2 samples (E23:H25 cells is a sample, E27:H29 cells is the other sample), each sample has 3 rows and 4 columns. So from shape information, we know (total samples, total rows in each sample, total columns in each sample).\n\nIn code, the shape information is often represented as tuple data structure. Which means we can also do negative indexing, ie:\n- shape at index -2 == column information\n- shape at index -1 == row information\n- shape at index 0 == sample information\n\n\nSum across any axis would collapse the specified axis. What do I mean by this?\n\nOriginally, our `a_b` tensor is of shape (2, 3, 4). If we *add all rows*, keeping everything else the same. Our resulting shape would be (2, **3**, 4) --> (2, **1**, 4)\n\n\n\n![image.png](attachment:image.png)\n\nYup, this below is the same. The only difference here is that we use index here. Above, we use negative indexing style. The same thing, just different way of writing, don't let it confuse you.\n\n![image.png](attachment:image.png)\n\nSimilarly, if we *add all columns*, keeping everything the same. Then our resulting shape would be (2, 3, **4**) --> (2, 3, **1**)\n\n![image.png](attachment:image.png)\n\nNow, if we *add all samples*, keeping everything else the same. Our result would be from shape (**2**, 3, 4) --> (**1**, 3, 4).\n\n# Sum across multiple axis\n\n![image.png](attachment:image.png)\n\nWe can also do sum across multiple axis. Remember that our original tensor is of shape (2, 3, 4), if we do sum operation across both rows and columns, then we would be *collapsing both of these axis*, keeping everything else the same. So the resulting tensor would be from shape (2, **3, 4**) --> (2, **1, 1**).\n\n\n\nAlso notice that the order in which we specify the axes does not matter. `.sum((-1, -2))` is the same as `.sum((-2, -1))`.\n\n![image.png](attachment:image.png)\n\nNow we *sum all samples and rows*, keeping everything else the same. The resulting tensor would be from (**2, 3,** 4) --> (**1, 1,** 4).\n\n\n![image.png](attachment:image.png)\n\nLastly, if we sum all samples and columns, then the resulting tensor would be from (**2**, 3, **4**) --> (**1**, 3, **1**). \n\nNotice that for resulting value 52, our excel formula is E23:H23 + E27:H27 ≈ we add everything from first row in sample 1, plus everything from first row in sample 2.\n\n\nHopefully, now it is easy to notice that any axis we choose to perform operations on would be *collapsed* to 1. Which means, when we collapsed all axes, it is equivalent to sum across everything in the tensor. ie in code, this is:\n\nwhich is the same as:\n\n\nAll above operations can be also performed using numpy arrays. For example, the equivalent summing across samples and rows in numpy is:\n\nVisualizing these tensors and formulas on excel makes it easier to for me to see what happen in the background. Hopefully, it is helpful to you too.\n","srcMarkdownNoYaml":"\n\n\n>Visualizing simple operations across arrays\n\nIn deep learning world, we are always working with arrays and tensors. They are data structure in which we store data for our model to train on. Both are multi-dimensional data structure and have similar functionality, but tensors had more restrictions than arrays.\n\nTensor must:\n- use a single basic numerical type for all components in the array.\n- can not be jagged. It is always regularly shaped multi-dimensional rectangular structure.\n\nI always had trouble trying to understand what exactly happen when we perform operations on any data structure that has higher dimension than a list (dimension of 1). \n\nSo, let's use Excel to visualize some basic operations on arrays (or tensors)! Say we have 2 tensors, a and b. Both of dimension of 3.\n\n![image-2.png](attachment:image-2.png)\n\n# Element wise operation\n\n![image-2.png](attachment:image-2.png)\n\nIf we subtract tensor a - tensor b, we are doing elementwise operation because both tensors a and b are of the same shape.\n\n\n# Sum across tensor\n\n![image.png](attachment:image.png)\n\nIf we sum across the whole tensor, we will get a scalar value (dimension 0). Scalar value is another name for *a number*.\n\n# Sum across axis\n\nNow, let's do sum operation across axis. Axis could be sample, row or column. Notice that our tensor `a_b` had shape of (2,3,4). This means it is made up of 2 samples (E23:H25 cells is a sample, E27:H29 cells is the other sample), each sample has 3 rows and 4 columns. So from shape information, we know (total samples, total rows in each sample, total columns in each sample).\n\nIn code, the shape information is often represented as tuple data structure. Which means we can also do negative indexing, ie:\n- shape at index -2 == column information\n- shape at index -1 == row information\n- shape at index 0 == sample information\n\n\nSum across any axis would collapse the specified axis. What do I mean by this?\n\nOriginally, our `a_b` tensor is of shape (2, 3, 4). If we *add all rows*, keeping everything else the same. Our resulting shape would be (2, **3**, 4) --> (2, **1**, 4)\n\n\n\n![image.png](attachment:image.png)\n\nYup, this below is the same. The only difference here is that we use index here. Above, we use negative indexing style. The same thing, just different way of writing, don't let it confuse you.\n\n![image.png](attachment:image.png)\n\nSimilarly, if we *add all columns*, keeping everything the same. Then our resulting shape would be (2, 3, **4**) --> (2, 3, **1**)\n\n![image.png](attachment:image.png)\n\nNow, if we *add all samples*, keeping everything else the same. Our result would be from shape (**2**, 3, 4) --> (**1**, 3, 4).\n\n# Sum across multiple axis\n\n![image.png](attachment:image.png)\n\nWe can also do sum across multiple axis. Remember that our original tensor is of shape (2, 3, 4), if we do sum operation across both rows and columns, then we would be *collapsing both of these axis*, keeping everything else the same. So the resulting tensor would be from shape (2, **3, 4**) --> (2, **1, 1**).\n\n\n\nAlso notice that the order in which we specify the axes does not matter. `.sum((-1, -2))` is the same as `.sum((-2, -1))`.\n\n![image.png](attachment:image.png)\n\nNow we *sum all samples and rows*, keeping everything else the same. The resulting tensor would be from (**2, 3,** 4) --> (**1, 1,** 4).\n\n\n![image.png](attachment:image.png)\n\nLastly, if we sum all samples and columns, then the resulting tensor would be from (**2**, 3, **4**) --> (**1**, 3, **1**). \n\nNotice that for resulting value 52, our excel formula is E23:H23 + E27:H27 ≈ we add everything from first row in sample 1, plus everything from first row in sample 2.\n\n\nHopefully, now it is easy to notice that any axis we choose to perform operations on would be *collapsed* to 1. Which means, when we collapsed all axes, it is equivalent to sum across everything in the tensor. ie in code, this is:\n\nwhich is the same as:\n\n\nAll above operations can be also performed using numpy arrays. For example, the equivalent summing across samples and rows in numpy is:\n\nVisualizing these tensors and formulas on excel makes it easier to for me to see what happen in the background. Hopefully, it is helpful to you too.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"visualizing_arrays.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.45","theme":"cosmo","title":"Visualizing Arrays using Excel","date":"6/23/2024","date-modified":"6/23/2024","categories":["array","numpy","tensor","excel"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}