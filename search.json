[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Suffix Array\n\n\n1 min\n\n\n\n\n\n\nNov 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBurrows-Wheeler Transform in Python\n\n\n3 min\n\n\n\n\n\n\nNov 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences between: PAM vs BLOSUM\n\n\n1 min\n\n\n\n\n\n\nOct 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSmith-Waterman Local Alignment using Python\n\n\n1 min\n\n\n\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCondensed A/B Test Summary\n\n\n1 min\n\n\n\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nExtract data from GEO2R\n\n\n2 min\n\n\n\n\n\n\nAug 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network from scratch using Excel\n\n\n6 min\n\n\n\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Arrays using Excel\n\n\n4 min\n\n\n\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sarah Hannes",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Download CV\n  \n\n      \n\n\nPython Pandas Tensorflow Keras Scikit-Learn\nLightGBM SQL MongoDB \n\n\n\nBottomless | Aug 2022 - Present\nJunior Data Scientist\nDHL | May 2021 – Oct 2021\nData Scientist Intern\nAccenture | Jul 2019 – Oct 2020\nQuality Auditor\n\n\n\nUniversity of Technology, Malaysia (UTM) | March 2022\nMaster of Science (Data Science)\nUniversity of Science, Malaysia (USM) | July 2016\nBachelor of Applied Biology, Hons (Biotechnology)"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Sarah Hannes",
    "section": "",
    "text": "Bottomless | Aug 2022 - Present\nJunior Data Scientist\nDHL | May 2021 – Oct 2021\nData Scientist Intern\nAccenture | Jul 2019 – Oct 2020\nQuality Auditor"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Sarah Hannes",
    "section": "",
    "text": "University of Technology, Malaysia (UTM) | March 2022\nMaster of Science (Data Science)\nUniversity of Science, Malaysia (USM) | July 2016\nBachelor of Applied Biology, Hons (Biotechnology)"
  },
  {
    "objectID": "blog/bwt_in_python.html",
    "href": "blog/bwt_in_python.html",
    "title": "Burrows-Wheeler Transform in Python",
    "section": "",
    "text": "Burrows-Wheeler Transform is a method used for pattern matching problem. We can use it to find all instances of substrings in the database that matches our query sequence.\nI recently learnt about Burrows-Wheeler Transform from the Advanced Data Structure playlist by Niema Moshiri. In this notebook, I tried to implement it using python.\nfrom collections import Counter\nimport pandas as pd\ndb = 'BANANA$'"
  },
  {
    "objectID": "blog/bwt_in_python.html#step-1-list-out-bwt-as-last-column-and-sorted-list-of-the-original-database-as-first-column",
    "href": "blog/bwt_in_python.html#step-1-list-out-bwt-as-last-column-and-sorted-list-of-the-original-database-as-first-column",
    "title": "Burrows-Wheeler Transform in Python",
    "section": "Step 1: List out BWT as last column and sorted list of the original database as first column",
    "text": "Step 1: List out BWT as last column and sorted list of the original database as first column\n\ndf = pd.DataFrame({'first': sorted(db), 'last': BWT})\ndf\n\n\n\n\n\n\n\n\nfirst\nlast\n\n\n\n\n0\n$\nA\n\n\n1\nA\nN\n\n\n2\nA\nN\n\n\n3\nA\nB\n\n\n4\nB\n$\n\n\n5\nN\nA\n\n\n6\nN\nA"
  },
  {
    "objectID": "blog/bwt_in_python.html#step-2-add-the-number-of-times-weve-seen-the-character-at-that-point-as-subscript",
    "href": "blog/bwt_in_python.html#step-2-add-the-number-of-times-weve-seen-the-character-at-that-point-as-subscript",
    "title": "Burrows-Wheeler Transform in Python",
    "section": "Step 2: Add the number of times we’ve seen the character at that point as subscript",
    "text": "Step 2: Add the number of times we’ve seen the character at that point as subscript\n\n### adding subscript for first column (sorted original database)\n\ndbcounter = Counter(db)\n\nsorted_db_subs = []\nfor c in sorted(db, reverse=True):\n    sorted_db_subs.append(c + str(dbcounter[c]))\n    dbcounter[c] = dbcounter[c] - 1\n\nsorted_db_subs = sorted(sorted_db_subs)\nsorted_db_subs\n\n['$1', 'A1', 'A2', 'A3', 'B1', 'N1', 'N2']\n\n\n\n### adding subscript for last column (BWT)\n\ndbcounter = Counter(BWT)\nprint(dbcounter)\n\nbwt_subs = []\nfor c in BWT[::-1]:\n    bwt_subs.append(c + str(dbcounter[c]))\n    dbcounter[c] = dbcounter[c] - 1\n\nbwt_subs = bwt_subs[::-1]\n\nCounter({'A': 3, 'N': 2, 'B': 1, '$': 1})\n\n\n\ndf['first_sub'] = sorted_db_subs\ndf['last_sub'] = bwt_subs\n\n\ndf\n\n\n\n\n\n\n\n\nfirst\nlast\nfirst_sub\nlast_sub\n\n\n\n\n0\n$\nA\n$1\nA1\n\n\n1\nA\nN\nA1\nN1\n\n\n2\nA\nN\nA2\nN2\n\n\n3\nA\nB\nA3\nB1\n\n\n4\nB\n$\nB1\n$1\n\n\n5\nN\nA\nN1\nA2\n\n\n6\nN\nA\nN2\nA3"
  },
  {
    "objectID": "blog/bwt_in_python.html#step-3-add-last-to-first-mapping",
    "href": "blog/bwt_in_python.html#step-3-add-last-to-first-mapping",
    "title": "Burrows-Wheeler Transform in Python",
    "section": "Step 3: Add last-to-first mapping",
    "text": "Step 3: Add last-to-first mapping\n\nMAPPING = {k:v for k,v in zip(df['first_sub'].values, range(len(df)))}\nMAPPING\n\n{'$1': 0, 'A1': 1, 'A2': 2, 'A3': 3, 'B1': 4, 'N1': 5, 'N2': 6}\n\n\n\ndf['L2F'] = df.apply(lambda row: MAPPING[row['last_sub']],axis=1)\ndf\n\n\n\n\n\n\n\n\nfirst\nlast\nfirst_sub\nlast_sub\nL2F\n\n\n\n\n0\n$\nA\n$1\nA1\n1\n\n\n1\nA\nN\nA1\nN1\n5\n\n\n2\nA\nN\nA2\nN2\n6\n\n\n3\nA\nB\nA3\nB1\n4\n\n\n4\nB\n$\nB1\n$1\n0\n\n\n5\nN\nA\nN1\nA2\n2\n\n\n6\nN\nA\nN2\nA3\n3\n\n\n\n\n\n\n\nWe can reconstruct our original database string from this preprocessed data. Here’s how:\nWe can start with the null termination character we added, we know it is in the first row, first_sub column, so we retrieve that first.\nRemember that as part of our preprocessing steps we do rotations of the original database string, and from that rotations we save the first column in first_sub and the last column in last_sub? So this tells us that first_sub and last_sub are connected: last_sub character comes before first_sub character.\n\n\n\nimage.png\n\n\nTo illustrate: 1. Start with null termination $1. 2. Find null termination $1 in last_sub (row 4). The next character follows it is the corresponding character in first_sub column (red arrow). Now the reconstructed string is $1 B1. 3. Find the last added character in the last_sub. Add its corresponding first_sub to the reconstructed string (blue arrow). Now the reconstructed string is $1 B1 A3. 4. Continue building the reconstructed string until we reached the character last_sub of first row. Why first row? because we started the reconstructed string with $1 – which is also the first_sub character in our preprocessed data’s first row.\n\nreconstruct = [df.loc[0,'first_sub']]\n\nwhile reconstruct[-1] != df.loc[0,'last_sub']:\n    last_char = reconstruct[-1]\n    next_index = df[df['last_sub']==last_char].index.values[0]\n    next_char = df.loc[df.index==next_index, 'first_sub'].values[0]\n    reconstruct.append(next_char)\n\nreconstructed_str_sub = ' '.join(reconstruct)\nreconstructed_str = ''.join([c[0] for c in reconstruct])\n\nprint('Reconstructed database string (with subscript):',reconstructed_str_sub)\nprint('Reconstructed database string:', reconstructed_str)\nprint('Original database string:', db)\n\nReconstructed database string (with subscript): $1 B1 A3 N2 A2 N1 A1\nReconstructed database string: $BANANA\nOriginal database string: BANANA$\n\n\nWe then move the null termination character to the end of the string and we can get back the original database."
  },
  {
    "objectID": "blog/diff_pam_blosum.html",
    "href": "blog/diff_pam_blosum.html",
    "title": "Differences between: PAM vs BLOSUM",
    "section": "",
    "text": "PAM and BLOSUM are both substitution matrix for amino acid. This is a high level overview of their differences.\n\nYou can download the image from here.\n\nfrom IPython.display import display, HTML\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\ndisplay(HTML('&lt;iframe frameborder=\"0\" style=\"width:100%;height:800px;\" src=\"https://viewer.diagrams.net/?tags=%7B%7D&lightbox=1&highlight=0000ff&edit=_blank&layers=1&nav=1&title=blosumVSpam.drawio#Uhttps%3A%2F%2Fdrive.google.com%2Fuc%3Fid%3D1fjtAgobn9ve0DzsDLo7zAyWCGsUtPXRA%26export%3Ddownload\"&gt;&lt;/iframe&gt;'));\n\n\n\n\n\nReference & credit:\n\nDr. Rob Edwards: BLAST playlist\nWikipedia: Tyrosine\nWikipedia: Phenylalanin\nHuman Genome Variation Society: Codon & amino acids"
  },
  {
    "objectID": "blog/feed_forward_nn_in_excel.html",
    "href": "blog/feed_forward_nn_in_excel.html",
    "title": "Neural Network from scratch using Excel",
    "section": "",
    "text": "Built (and train) simple neural network using Excel solver\nLet’s make a simple neural network using Excel. We are using the classic Iris dataset for this exercise.\nThe dataset has 6 columns and 150 rows. It is a balanced dataset with 3 categorical targets (Iris-setosa, Iris-versicolor, Iris-virginica) with 50 rows belonging to each target species. We are trying to predict the flower species of each row, based on its physical attributes (SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm)."
  },
  {
    "objectID": "blog/feed_forward_nn_in_excel.html#matrix-multiplication",
    "href": "blog/feed_forward_nn_in_excel.html#matrix-multiplication",
    "title": "Neural Network from scratch using Excel",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n 1. We can also achieve the same thing using matrix multiplication formula MMULT(all cells in features table, all cells in params table). Notice that our PARAMS now is transposed. Previously our coefficient values are in row 6 and 7, now they are in column I and J. \n\nHere is the result from solver. Notice that we get the same result (0.03) as previous."
  },
  {
    "objectID": "blog/ab_test.html",
    "href": "blog/ab_test.html",
    "title": "Condensed A/B Test Summary",
    "section": "",
    "text": "Condensed summary of A/B Test course by Data36. You can download the mind map here.\n\n\nfrom IPython.display import display, HTML\n\ndisplay(HTML('&lt;iframe style=\"width:100%;height:1500px;border: 1px solid #d0d0d0;border-radius: 6px;\" src=\"https://www.mindomo.com/mindmap/ab-test-c8a1fbd9f65e4b16be9d1060bee2d88e\" frameborder=\"0\" allowfullscreen&gt;Your browser does not support frames. &lt;a href=\"https://www.mindomo.com/mindmap/ab-test-c8a1fbd9f65e4b16be9d1060bee2d88e\" target=\"_blank\"&gt;View&lt;/a&gt; this map on its original site. It was created using &lt;a href=\"https://www.mindomo.com\" target=\"_blank\"&gt;Mindomo&lt;/a&gt;.&lt;/iframe&gt;'));\n\nYour browser does not support frames. &lt;a href=\"https://www.mindomo.com/mindmap/ab-test-c8a1fbd9f65e4b16be9d1060bee2d88e\" target=\"_blank\"&gt;View&lt;/a&gt; this map on its original site. It was created using &lt;a href=\"https://www.mindomo.com\" target=\"_blank\"&gt;Mindomo&lt;/a&gt;.\n\n\n\nReference & credit:\n\nData36: A/B Testing Course (Full Online Course) playlist"
  },
  {
    "objectID": "til/190724_how-to-save-load-fastai-model.html",
    "href": "til/190724_how-to-save-load-fastai-model.html",
    "title": "How to Save & Load FastAI Model",
    "section": "",
    "text": "Save model using learn.export(checkpoint_path). Load using learn = load_learner(checkpoint_path)\n\nI had a hard time figuring out how to save and load trained fastai model. So, this is a guide to remind myself of what I’ve tried (and failed), and what works.\n\nimport pickle\nimport gc\nimport os\nimport glob\nfrom typing import Union\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom fastai.vision.all import *\n\n\nimport fastai\nfastai.__version__\n\n'2.7.15'\n\n\n\ndef unpickle(fp):\n    print('loading', fp)\n    with open(fp, 'rb') as f:\n        x = pd.read_pickle(f)\n        # x = pickle.load(f, encoding='ASCII')\n    return x\n\n\ndef unpickle_multiple_pd(path:Union[str,list], drop_dup_on_cols:Union[None, list]) -&gt; pd.DataFrame:\n    \"\"\"unpickle multiple pandas dataframes\n    input & output = pandas df\n\n    if `drop_dup_on_cols` is not None, will drop duplicate on `drop_dup_on_cols` cols.\n    \"\"\"\n    import gc\n    import glob\n    \n    print('path', type(path), path)\n    if isinstance(path, list):\n        filenames = path\n    else:\n\n        filenames = list(glob.glob(path))\n        \n    print('loading', filenames)\n    if len(filenames) &gt; 1:\n        \n        loaded_file = []\n\n        for i,f in enumerate(filenames):\n            if f != '':\n                try:\n                    loaded_file.append(unpickle(f))\n                    print('i', i)\n                    gc.collect()\n                except:\n                    print('loading error')\n                    continue\n        gc.collect()\n        df = pd.concat(loaded_file)\n        if drop_dup_on_cols is not None:\n            df = df.drop_duplicates(subset=drop_dup_on_cols)\n        return df.reset_index(drop=True)\n    return unpickle(filenames[0])\n\n\n\ndef save_pickle(fp:str, x) -&gt; None:\n    with open(fp, 'wb') as f:\n        pickle.dump(x, f)\n    print('saved pickle', fp)\n\n\nfp = '/kaggle/input/ordergen-transformers-prepostprocesd-17072024/Archive2/20210104_20231031_trainxyz_testxyz_ori.pkl'\nXtrain, ytrain, train_annos, Xtest, ytest, test_annos = unpickle(fp)\n\nloading /kaggle/input/ordergen-transformers-prepostprocesd-17072024/Archive2/20210104_20231031_trainxyz_testxyz_ori.pkl\n\n\n\nprint(Xtrain.shape)\nXtrain\n\n(839200, 744)\n\n\narray([[ 0.8008967 ,  0.8019981 ,  0.70472926, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.37820956,  0.37688217,  0.37682053, ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.30258572, -0.3024994 , -0.3730603 , ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [-1.        , -1.        , -1.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.        , -1.        , -1.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.        , -1.        , -1.        , ...,  0.        ,\n         0.        ,  0.6666667 ]], dtype=float32)\n\n\n\nprint(ytrain.shape)\nytrain\n\n(839200, 1)\n\n\narray([[0],\n       [0],\n       [0],\n       ...,\n       [0],\n       [0],\n       [0]], dtype=uint8)\n\n\n\ndef pass_index(idx):\n    return idx\n\ndef get_x(i):\n    return image[i]\n\ndef get_y(i):\n    return label[i]\n\n\nSLICE = 1000 # for demonstration, we will work on small sample slice only\n\nimage = Xtrain[:SLICE]\nlabel = ytrain[:SLICE,0] # select the first axis (col) because my labels are in 2 dimensional ie (total rows, 1)\n\ndblock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=pass_index,\n    get_x=get_x,\n    get_y=get_y)\n\n# pass in a list of index\nnum_images = image.shape[0]\ndls = dblock.dataloaders(list(range(num_images)))\n\nNote: We won’t be able to save the model if we have nested functions. Like below. Notice we have pass_index, get_x, get_y functions inside the make_dataloaders_from_numpy_data. The workaround is to move it out of the function.\n\ndef make_dataloaders_from_numpy_data(image, label):\n    def pass_index(idx):\n        return idx\n\n    def get_x(i):\n        return image[i]\n\n    def get_y(i):\n        return label[i]\n\n    dblock = DataBlock(\n        blocks=(ImageBlock, CategoryBlock),\n        get_items=pass_index,\n        get_x=get_x,\n        get_y=get_y)\n\n    # pass in a list of index\n    num_images = image.shape[0]\n    dls = dblock.dataloaders(list(range(num_images)))\n\n    return dls\n\ndls = make_dataloaders_from_numpy_data(Xtrain, ytrain[:,0])\n\n\nTrain model\n\nlearn = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00&lt;00:00, 133MB/s] \n\n\n\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.690889\n0.820386\n0.810000\n00:48\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.534998\n0.656172\n0.805000\n01:04\n\n\n1\n0.519913\n0.644092\n0.660000\n01:05\n\n\n2\n0.501660\n0.590537\n0.755000\n01:04\n\n\n3\n0.481192\n0.602440\n0.800000\n01:04\n\n\n4\n0.448506\n0.559592\n0.775000\n01:05\n\n\n5\n0.395029\n0.629317\n0.735000\n01:05\n\n\n6\n0.354913\n0.627367\n0.800000\n01:04\n\n\n7\n0.302945\n0.688665\n0.780000\n01:04\n\n\n8\n0.265921\n0.668892\n0.790000\n01:05\n\n\n9\n0.231195\n0.661298\n0.785000\n01:05\n\n\n\n\n\nFor fun, let’s plot the model’s loss, and confusion matrix.\n\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSave trained model\nI saved my trained model in 3 different file extensions (1 of them is actually saved without any specified file extension).\n\ncheckpoint_path = '/kaggle/working/my_fastai_model_export'\nlearn.export(checkpoint_path)\n\n\ncheckpoint_path = '/kaggle/working/my_fastai_model_pth_export.pth'\nlearn.export(checkpoint_path)\n\n\n\ncheckpoint_path = '/kaggle/working/my_fastai_pkl_export.pkl'\nlearn.export(checkpoint_path)\n\n\n\nLoad trained model & get batch predictions\nTo load trained model, I restart the kernel so we can test that this actually works. I did not rerun any code cells above, just the importing libraries cell.\nFirst of, we need to reinitialize all our dataset preprocessing things. But instead of working with the same training data, we will load out of sample test set.\n\n\nfp = '/kaggle/input/ordergen-transformers-prepostprocesd-17072024/Archive2/20240429_20240503_testxyz_ori.pkl'\ntest_features, test_targets, annotations = unpickle(fp)\n\nloading /kaggle/input/ordergen-transformers-prepostprocesd-17072024/Archive2/20240429_20240503_testxyz_ori.pkl\n\n\n\nprint(test_features.shape)\ntest_features\n\n(26856, 744)\n\n\narray([[ 0.6689392 ,  0.6722139 ,  0.66988313, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.56092703,  0.5576653 ,  0.5589551 , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.1795841 , -0.18068182, -0.17959571, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [ 0.25185028,  0.25209376,  0.25152162, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.8822221 ,  0.88193876,  0.8785461 , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.5615684 , -0.6948581 , -0.68838125, ...,  0.        ,\n         0.        ,  0.        ]], dtype=float32)\n\n\n\nprint(test_targets.shape)\ntest_targets\n\n(26856, 1)\n\n\narray([[0],\n       [0],\n       [0],\n       ...,\n       [0],\n       [0],\n       [0]], dtype=uint8)\n\n\nWe need to re-define the same functions and DataBlock and dataloaders we used to trained the model.\n\ndef pass_index(idx):\n    return idx\n\ndef get_x(i):\n    return image[i]\n\ndef get_y(i):\n    return label[i]\n\nBut this time, using the new test set.\n\nSLICE = 1000 # for demonstration, we will work on small sample slice only\nimage = test_features[:SLICE]\nlabel = test_targets[:SLICE,0] # select the first axis because my labels are in 2 dimensional ie (total rows, 1)\n\n\n\n\ndblock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=pass_index,\n    get_x=get_x,\n    get_y=get_y)\n\n# pass in a list of index\nnum_images = image.shape[0]\ndls = dblock.dataloaders(list(range(num_images)))\n\nLet’s test loading all our saved model one by one.\n\n\ncheckpoint_path1 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_export'\n\n\nlearn1 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn1 = load_learner(checkpoint_path1)\n\ntest_dl1 = learn1.dls.test_dl(test_features[:SLICE])\n\n# get batch prediction\nypreds1, _ = learn1.get_preds(dl=test_dl1)\nypreds1\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00&lt;00:00, 61.4MB/s]\n\n\n\n\n\n\n\n\n\ntensor([[9.5914e-01, 4.0856e-02],\n        [8.6308e-01, 1.3692e-01],\n        [4.6716e-01, 5.3284e-01],\n        ...,\n        [9.9386e-01, 6.1434e-03],\n        [9.2105e-01, 7.8951e-02],\n        [9.9948e-01, 5.2483e-04]])\n\n\n\n\ncheckpoint_path2 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_pth_export.pth'\n\n\nlearn2 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn2 = load_learner(checkpoint_path2)\n\ntest_dl2 = learn2.dls.test_dl(test_features[:SLICE])\n\n# get batch prediction\nypreds2, _ = learn2.get_preds(dl=test_dl2)\nypreds2\n\n\n\n\n\n\n\n\ntensor([[9.5914e-01, 4.0856e-02],\n        [8.6308e-01, 1.3692e-01],\n        [4.6716e-01, 5.3284e-01],\n        ...,\n        [9.9386e-01, 6.1434e-03],\n        [9.2105e-01, 7.8951e-02],\n        [9.9948e-01, 5.2483e-04]])\n\n\n\n\ncheckpoint_path3 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_pkl_export.pkl'\n\n\nlearn3 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn3 = load_learner(checkpoint_path3)\n\ntest_dl3 = learn3.dls.test_dl(test_features[:SLICE])\n\n# get batch prediction\nypreds3, _ = learn3.get_preds(dl=test_dl3)\nypreds3\n\n\n\n\n\n\n\n\ntensor([[9.5914e-01, 4.0856e-02],\n        [8.6308e-01, 1.3692e-01],\n        [4.6716e-01, 5.3284e-01],\n        ...,\n        [9.9386e-01, 6.1434e-03],\n        [9.2105e-01, 7.8951e-02],\n        [9.9948e-01, 5.2483e-04]])\n\n\n\n\n(…What doesn’t work)\nUsing learn.load(checkpoint_path) does not work. For some reason I get FileNotFoundError but they clearly exist…\n\n\ncheckpoint_path01 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_export'\nlearn01 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn01.load(checkpoint_path01)  # this does not work\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[16], line 3\n      1 checkpoint_path01 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_export'\n      2 learn01 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n----&gt; 3 learn01.load(checkpoint_path01)  # this does not work\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/learner.py:420, in load(self, file, device, **kwargs)\n    418 file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n    419 distrib_barrier()\n--&gt; 420 load_model(file, self.model, self.opt, device=device, **kwargs)\n    421 return self\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51, in load_model(file, model, opt, with_opt, device, strict, **torch_load_kwargs)\n     49 if isinstance(device, int): device = torch.device('cuda', device)\n     50 elif device is None: device = 'cpu'\n---&gt; 51 state = torch.load(file, map_location=device, **torch_load_kwargs)\n     52 hasopt = set(state)=={'model', 'opt'}\n     53 model_state = state['model'] if hasopt else state\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:986, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n    983 if 'encoding' not in pickle_load_args.keys():\n    984     pickle_load_args['encoding'] = 'utf-8'\n--&gt; 986 with _open_file_like(f, 'rb') as opened_file:\n    987     if _is_zipfile(opened_file):\n    988         # The zipfile reader is going to advance the current file position.\n    989         # If we want to actually tail call to torch.jit.load, we need to\n    990         # reset back to the original position.\n    991         orig_position = opened_file.tell()\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:435, in _open_file_like(name_or_buffer, mode)\n    433 def _open_file_like(name_or_buffer, mode):\n    434     if _is_path(name_or_buffer):\n--&gt; 435         return _open_file(name_or_buffer, mode)\n    436     else:\n    437         if 'w' in mode:\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:416, in _open_file.__init__(self, name, mode)\n    415 def __init__(self, name, mode):\n--&gt; 416     super().__init__(open(name, mode))\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_export.pth'\n\n\n\n\n\ncheckpoint_path02 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_pth_export.pth'\nlearn02 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn02.load(checkpoint_path02)  # this does not work\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[17], line 3\n      1 checkpoint_path02 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_pth_export.pth'\n      2 learn02 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n----&gt; 3 learn02.load(checkpoint_path02)  # this does not work\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/learner.py:420, in load(self, file, device, **kwargs)\n    418 file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n    419 distrib_barrier()\n--&gt; 420 load_model(file, self.model, self.opt, device=device, **kwargs)\n    421 return self\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51, in load_model(file, model, opt, with_opt, device, strict, **torch_load_kwargs)\n     49 if isinstance(device, int): device = torch.device('cuda', device)\n     50 elif device is None: device = 'cpu'\n---&gt; 51 state = torch.load(file, map_location=device, **torch_load_kwargs)\n     52 hasopt = set(state)=={'model', 'opt'}\n     53 model_state = state['model'] if hasopt else state\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:986, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n    983 if 'encoding' not in pickle_load_args.keys():\n    984     pickle_load_args['encoding'] = 'utf-8'\n--&gt; 986 with _open_file_like(f, 'rb') as opened_file:\n    987     if _is_zipfile(opened_file):\n    988         # The zipfile reader is going to advance the current file position.\n    989         # If we want to actually tail call to torch.jit.load, we need to\n    990         # reset back to the original position.\n    991         orig_position = opened_file.tell()\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:435, in _open_file_like(name_or_buffer, mode)\n    433 def _open_file_like(name_or_buffer, mode):\n    434     if _is_path(name_or_buffer):\n--&gt; 435         return _open_file(name_or_buffer, mode)\n    436     else:\n    437         if 'w' in mode:\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:416, in _open_file.__init__(self, name, mode)\n    415 def __init__(self, name, mode):\n--&gt; 416     super().__init__(open(name, mode))\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_model_pth_export.pth.pth'\n\n\n\n\n\ncheckpoint_path03 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_pkl_export'\nlearn03 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn03.load(checkpoint_path03)  # this does not work\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[26], line 3\n      1 checkpoint_path03 = '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_pkl_export'\n      2 learn03 = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n----&gt; 3 learn03.load(checkpoint_path03)  # this does not work\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/learner.py:420, in load(self, file, device, **kwargs)\n    418 file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n    419 distrib_barrier()\n--&gt; 420 load_model(file, self.model, self.opt, device=device, **kwargs)\n    421 return self\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51, in load_model(file, model, opt, with_opt, device, strict, **torch_load_kwargs)\n     49 if isinstance(device, int): device = torch.device('cuda', device)\n     50 elif device is None: device = 'cpu'\n---&gt; 51 state = torch.load(file, map_location=device, **torch_load_kwargs)\n     52 hasopt = set(state)=={'model', 'opt'}\n     53 model_state = state['model'] if hasopt else state\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:986, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n    983 if 'encoding' not in pickle_load_args.keys():\n    984     pickle_load_args['encoding'] = 'utf-8'\n--&gt; 986 with _open_file_like(f, 'rb') as opened_file:\n    987     if _is_zipfile(opened_file):\n    988         # The zipfile reader is going to advance the current file position.\n    989         # If we want to actually tail call to torch.jit.load, we need to\n    990         # reset back to the original position.\n    991         orig_position = opened_file.tell()\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:435, in _open_file_like(name_or_buffer, mode)\n    433 def _open_file_like(name_or_buffer, mode):\n    434     if _is_path(name_or_buffer):\n--&gt; 435         return _open_file(name_or_buffer, mode)\n    436     else:\n    437         if 'w' in mode:\n\nFile /opt/conda/lib/python3.10/site-packages/torch/serialization.py:416, in _open_file.__init__(self, name, mode)\n    415 def __init__(self, name, mode):\n--&gt; 416     super().__init__(open(name, mode))\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/dummy_fastai_model/other/test2/1/my_fastai_pkl_export.pth'\n\n\n\n\n\nChecking our ypreds\n\n# probabilities for class0\npd.DataFrame(ypreds1)[0].hist()\n\n\n\n\n\n\n\n\n\n# probabilities for class 1\npd.DataFrame(ypreds1)[1].hist()\n\n\n\n\n\n\n\n\nAll is well, but for some reason, I could not plot a confusion matrix.\n\ninterp = ClassificationInterpretation.from_learner(learn3)\ninterp.plot_confusion_matrix()\n\n\"\"\"\nTraceback:\n{\n    \"name\": \"ValueError\",\n    \"message\": \"not enough values to unpack (expected 3, got 2)\",\n    \"stack\": \"---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[25], line 2\n      1 interp = ClassificationInterpretation.from_learner(learn3)\n----&gt; 2 interp.plot_confusion_matrix()\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/interpret.py:130, in ClassificationInterpretation.plot_confusion_matrix(self, normalize, title, cmap, norm_dec, plot_txt, **kwargs)\n    128 \\\"Plot the confusion matrix, with `title` and using `cmap`.\\\"\n    129 # This function is mainly copied from the sklearn docs\n--&gt; 130 cm = self.confusion_matrix()\n    131 if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    132 fig = plt.figure(**kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/fastai/interpret.py:114, in ClassificationInterpretation.confusion_matrix(self)\n    112 \\\"Confusion matrix as an `np.ndarray`.\\\"\n    113 x = torch.arange(0, len(self.vocab))\n--&gt; 114 _,targs,decoded = self.learn.get_preds(dl=self.dl, with_decoded=True, with_preds=True, \n    115                                        with_targs=True, act=self.act)\n    116 d,t = flatten_check(decoded, targs)\n    117 cm = ((d==x[:,None]) & (t==x[:,None,None])).long().sum(2)\n\nValueError: not enough values to unpack (expected 3, got 2)\"\n}\n\"\"\"\n\n\n\nConclusion\nThis is all still a bit of a mystery to me. I just started learning to use the library, but as of now it feels like the API is not very stable. I had to experiment a lot of times to get the trained model working. And it is puzzling that I did not run into any error in another notebook. Here is what I did in another notebook that I could not successfully replicate here.\n# load data and train model..\n\n# save model\ncheckpoint_path = 'fastai_timeseries.pkl'\nlearn.export(checkpoint_path)\n\n# I restart kernel here before continuing below.\n\n# redefine everything\nimage = test_features\nlabel = test_targets[:,0]\n\ndblock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=pass_index,\n    get_x=get_x,\n    get_y=get_y)\n\nnum_images = image.shape[0]\ndls = dblock.dataloaders(list(range(num_images)))\n\n# init learn\nlearn = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n\n# load model\ncheckpoint_path = '/kaggle/input/ordergen_timeseries_fastai/other/default/1/fastai_timeseries'\nlearn.load(checkpoint_path)        #### &lt;-------- diff is here\nSo, in short:\n\nWe save model by learn.export(checkpoint_path)\nThe file extension for checkpoint_path does not matter. When I omit the file extension entirely, we can still load and get predictions. Here is what I tried as checkpoint_path: [‘model’, ‘model.pth’, ‘model.pkl’].\nWe need to redefine all functions we used to trained the model (ie get_x, get_y, …).\nWe load model by:\n\ncheckpoint_path = any one of ['model', 'model.pth', 'model.pkl']\n\n# load model\nlearn = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn = load_learner(checkpoint_path)\n\n# init test dataloader\ntest_dl = learn.dls.test_dl(test_features)\n\n# get batch prediction\nypreds, _ = learn.get_preds(dl=test_dl)"
  },
  {
    "objectID": "til/310824_using_postgres.html",
    "href": "til/310824_using_postgres.html",
    "title": "Postgresql JOIN USING vs JOIN ON 🥞",
    "section": "",
    "text": "I recently learnt that we can directly use USING() clause as shorthand when joining tables in Postgresql. Here is the an excerpt from the documentation.\n[Click on the image to check the full documentation] \n\n--  Pets Table\nCREATE TABLE pets(id INT, type VARCHAR);\nINSERT INTO pets VALUES(1, 'dog');\nINSERT INTO pets VALUES(2, 'bird');\nINSERT INTO pets VALUES(3, 'cat');\nINSERT INTO pets VALUES(4, 'monkey');\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- \n\n--  Owner Table\nCREATE TABLE owner(id INT, name VARCHAR, pet_id INT);\nINSERT INTO owner VALUES(1, 'Sarah', 1);\nINSERT INTO owner VALUES(2, 'Bob', 2);\nINSERT INTO owner VALUES(3, 'Emily', 3);\nINSERT INTO owner VALUES(4, 'John', NULL);\n\n\n\n\nimage.png\n\n\nLet’s use the tables above as an example. Say we want to merge pet_id from both of the tables to find the pet type for each person listed in Owner table.\nAn option is to use USING(pet_id) clause. This is similar to JOIN ... ON owner.pet_id = pets.pet_id but will combine all resulting unique ids from both table.\n\n--  JOIN with USING\n\nSELECT pet_id, type, name\nFROM owner\nFULL JOIN pets USING(pet_id);\n\n\n\n\nimage.png\n\n\nWe can get the same result if above it we use normal JOIN ON... with CASE clause.. but this is definitely more wordy…\n\n-- Normal JOIN ON... with CASE\n\nSELECT CASE\n        WHEN o.pet_id IS NULL THEN p.pet_id\n        ELSE o.pet_id\n        END AS pet_id,\n        p.type, o.name\n        FROM OWNER AS o\n        FULL JOIN pets AS p\nON o.pet_id = p.pet_id\n\n\n\n\nimage.png"
  },
  {
    "objectID": "til/200624_numpy_datablock.html",
    "href": "til/200624_numpy_datablock.html",
    "title": "Creating DataBlock from Numpy Array",
    "section": "",
    "text": "Feed list of dict into DataBlock\n\nTLDR; Need to prepare our data into list of dictionaries for each sample, eg L([{x: feature1, y: label1},  {x: feature2, y: label2},  {x: featuren, y: labeln} ]) format and feed the function into get_image param of DataBlock.\n\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom fastai.data.core import Datasets\nfrom fastai.vision.all import *\n\n\nLoad data\n\n# ref: https://www.kaggle.com/code/drkaggle22/digit-recognizer-solution-99-accuracy?scriptVersionId=181451739&cellId=3\nimport struct\n\ndef read_idx(filename):\n    with open(filename, 'rb') as f:\n        zero, data_type, dims= struct.unpack('&gt;HBB', f.read(4))\n        shape = tuple(struct.unpack('&gt;I', f.read(4))[0] for d in range(dims))\n        \n        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n\ndef load_mnist(image_path, label_path):\n    images = read_idx(image_path)\n    labels = read_idx(label_path)\n    return images, labels\n\n\n\ntrain_image_path = '/kaggle/input/mnist-dataset/train-images-idx3-ubyte/train-images-idx3-ubyte'\ntrain_label_path = '/kaggle/input/mnist-dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte'\ntest_image_path =  '/kaggle/input/mnist-dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte'\ntest_label_path =  '/kaggle/input/mnist-dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte'\n\n\ntrain_images, train_labels = load_mnist(train_image_path, train_label_path)\ntest_images, test_labels = load_mnist(test_image_path, test_label_path)\nprint(f'Train images shape: {train_images.shape}')\nprint(f'Train labels shape: {train_labels.shape}')\nprint(f'Test images shape: {test_images.shape}')\nprint(f'Test labels shape: {test_labels.shape}')\n\nTrain images shape: (60000, 28, 28)\nTrain labels shape: (60000,)\nTest images shape: (10000, 28, 28)\nTest labels shape: (10000,)\n\n\n\nfrom collections import Counter\nprint(Counter(train_labels))\nn_classes = len(Counter(train_labels))\nprint('n_classes:', n_classes)\n\nCounter({1: 6742, 7: 6265, 3: 6131, 2: 5958, 9: 5949, 0: 5923, 6: 5918, 8: 5851, 4: 5842, 5: 5421})\nn_classes: 10\n\n\n\n\ndef tensor_to_labelled_pil_image(tensor: np.ndarray, labels=None) -&gt; list:\n    ''' ref: https://www.kaggle.com/code/pemtaira/digit-recognizer-fastai-v2-2020\n    shape image shape (total sample, height, width) into (total sample, 3, height, width),\n    save into dictionary (x: reshaped img, y: label). Append dictionary to list. return list.\n    '''\n    reshaped = tensor.reshape(-1, 28, 28) #  (total sample, 28, 28) --&gt; (total sample, 28, 28)\n    reshaped = np.stack((reshaped,) *3, axis = 1) # (total sample, 28, 28) --&gt; (total sample, 3, 28, 28)\n    image_arr = []\n    \n    # loop each reshaped images, convert to float tensor, convert to PILImage, save as dictionary, append to list\n    for idx, current_image in enumerate(reshaped):\n        img = torch.tensor(current_image, dtype=torch.float) / 255.\n        img = PILImage(to_image(img))\n        \n        final_data = None\n\n        if (labels is None):\n            final_data = {'x': img, 'y': None}\n        else:\n            final_data = {'x': img, 'y': labels[idx]}\n\n        image_arr.append(final_data)\n\n    return image_arr\n\n\ndef get_image(l:list) -&gt; L:\n    \"\"\"\n    returns list of [{'x': feature tensor, 'y': class label},\n                    {...}, {...} ]\n    L is fastai's implementation of list\n    \"\"\"\n    features = l[0]\n    labels = l[1]\n    all_imgs = tensor_to_labelled_pil_image(features, labels)\n    return L(all_imgs)\n    \n\n\ndef get_y_fromdict(item):\n    \"\"\"get y from each sample dictionary returned from get_image()\"\"\"\n    return item['y']\n\ndef get_x_fromdict(item):\n    \"\"\"get x from each sample dictionary returned from get_image()\"\"\"\n    return item['x']\n\n\n\nInitialize DataBlock\nblocks=(ImageBlock(cls=PILImage), CategoryBlock) &gt; Here we specify that our input data is an image and of class PILImage, our label is categorical\nget_items=get_image &gt; Function where we return list of {x:features, y:label} dictionary for all our samples\nsplitter=RandomSplitter(valid_pct=0.2, seed=42) &gt; Describe how we want to split our data; Here we want to split train and test data into 80-20 split randomly. We specify seed to have reproducible result for each run.\nget_x=get_x_fromdict &gt; Function to extract features from list returned from get_image() function. Note, we could also use lambda function here get_x = (lambda item: item['x']).\nget_y=get_y_fromdict &gt; Function to extract label from list returned from get_image() function. Note, we could also use lambda function here get_y = (lambda item: item['y']).\nNote that if we use lambda function when initializing DataBlock, we might need to use dill library to export our model.\n\nmnist_db = DataBlock(\n    blocks=(ImageBlock(cls=PILImage), CategoryBlock), \n    get_items=get_image, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=get_y_fromdict,#(lambda item: item['y']),\n    get_x=get_x_fromdict #(lambda item: item['x'])\n)\n\n\n# checking featues and labels shapes\nprint(train_images.shape)\nprint(train_labels.shape)\n\n(60000, 28, 28)\n(60000,)\n\n\n\n# stacking both train and test sets' features\n\nprint(train_images.shape)\nprint(test_images.shape)\nnp.vstack([train_images, test_images]).shape\n\n(60000, 28, 28)\n(10000, 28, 28)\n\n\n(70000, 28, 28)\n\n\n\n# stacking both train and test sets\nprint(train_labels.shape)\nprint(test_labels.shape)\nnp.hstack([train_labels, test_labels]).shape\n\n(60000,)\n(10000,)\n\n\n(70000,)\n\n\nThis is how our data is reshaped in tensor_to_labelled_pil_image() function.\n\nfeatures = np.vstack([train_images, test_images])\nfeatures_reshaped = features.reshape(-1, 28, 28)\nfeatures_reshaped_stacked = np.stack((features_reshaped,) *3, axis = 1)\n\nprint('features.shape', features.shape)\nprint('features_reshaped.shape', features_reshaped.shape)\nprint('features_reshaped_stacked.shape', features_reshaped_stacked.shape)\n\nfeatures.shape (70000, 28, 28)\nfeatures_reshaped.shape (70000, 28, 28)\nfeatures_reshaped_stacked.shape (70000, 3, 28, 28)\n\n\n\n\nQuick plot\n\n# ref: https://stackoverflow.com/a/59296746\nimport matplotlib.pyplot as plt\nfig, axes = plt.subplots(10,10, figsize=(28,28))\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(features_reshaped[i])\n\n\n\n\n\n\n\n\nLoad our source data\n\ndls = mnist_db.dataloaders([np.vstack([train_images, test_images]),\n                            np.hstack([train_labels, test_labels])])\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n\nTrain model\n\nlearn = vision_learner(dls, resnet18, metrics=[error_rate, accuracy])\nlearn.fine_tune(10)\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00&lt;00:00, 146MB/s]\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\naccuracy\ntime\n\n\n\n\n0\n0.714643\n0.483854\n0.155143\n0.844857\n04:06\n\n\n\n\n\n\n\n\n\n\n    \n      \n      90.00% [9/10 1:10:59&lt;07:53]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\naccuracy\ntime\n\n\n\n\n0\n0.170800\n0.091101\n0.026429\n0.973571\n08:18\n\n\n1\n0.098211\n0.057546\n0.018071\n0.981929\n07:50\n\n\n2\n0.070756\n0.043570\n0.013071\n0.986929\n07:54\n\n\n3\n0.045105\n0.036998\n0.010214\n0.989786\n07:51\n\n\n4\n0.034318\n0.037484\n0.010214\n0.989786\n07:51\n\n\n5\n0.032253\n0.031844\n0.007857\n0.992143\n07:49\n\n\n6\n0.013959\n0.029695\n0.006714\n0.993286\n07:47\n\n\n7\n0.006643\n0.028861\n0.006643\n0.993357\n07:48\n\n\n8\n0.002887\n0.027575\n0.006143\n0.993857\n07:48\n\n\n\n\n\n    \n      \n      22.83% [50/219 00:06&lt;00:21 0.0014]\n    \n    \n\n\nIOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n\n\n\n\nSave model\n\nlearn.export('model2.pkl')\n\nIf we use lambda function when initializing DataBlock, we can use dill to save model. Eg:\n\n\nimport dill\nlearn.export('model2.pkl', pickle_module=dill)"
  },
  {
    "objectID": "til/160824_docker_cache.html",
    "href": "til/160824_docker_cache.html",
    "title": "Clear docker cache",
    "section": "",
    "text": "A reminder on how to clear docker cache.\n\n\n\nimage-2.png\n\n\n\nCheck diskspace used by Docker\ndocker system df\n\n\nRemove Build Cache\ndocker builder prune"
  },
  {
    "objectID": "til/130624_fastai_AttributeError.html",
    "href": "til/130624_fastai_AttributeError.html",
    "title": "TabularPandas AttributeError: classes",
    "section": "",
    "text": "Specify procs TabularPandas(..., procs = [Categorify]) when you have categorical columns\n\n\n\n\n\n\n\nNote\n\n\n\nThis post was written using: - pandas: 2.2.2 - fastai: 2.7.15\n\n\n\nimport pandas as pd\nfrom fastai.tabular.all import *\n\n\n# looking at unique values in each columns to split categorical / continuous features\nfor k in df.keys():\n    print(f\"Column {k}:\\n{Counter(df[k])}\")\n    print()\n\nColumn a:\nCounter({2.0: 8435, 1.0: 2580, 3.0: 2011})\n\nColumn b:\nCounter({12.0: 9853, 32.0: 2911, 80.0: 87, 16.0: 72, 11.0: 47, 8.0: 28, 10.0: 25, 40.0: 3})\n\nColumn c:\nCounter({0: 1579, 5: 1517, 6: 1271, 7: 1213, 4: 1211, 8: 1081, 3: 898, 9: 831, 10: 682, 2: 608, 1: 342, 11: 278, 14: 216, 12: 206, 16: 184, 13: 165, 15: 145, 17: 131, 18: 94, 19: 88, 20: 66, 21: 57, 23: 54, 29: 24, 26: 18, 24: 16, 27: 16, 22: 12, 30: 12, 25: 7, 28: 4})\n\nColumn d:\nCounter({15.0: 7521, -1.0: 1433, 8.0: 374, 0.0: 372, 7.0: 365, 9.0: 334, 10.0: 319, 6.0: 316, 5.0: 272, 11.0: 264, 4.0: 241, 12.0: 220, 3.0: 217, 13.0: 205, 14.0: 176, 2.0: 170, 1.0: 164, -3.0: 14, -2.0: 4, -4.0: 3, -27.0: 3, -5.0: 3, -22.0: 2, -26.0: 2, -30.0: 2, -16.0: 2, -7.0: 2, -17.0: 2, -21.0: 1, -23.0: 1, -25.0: 1, -28.0: 1, -31.0: 1, -32.0: 1, -53.0: 1, -56.0: 1, -57.0: 1, -58.0: 1, -59.0: 1, -88.0: 1, -93.0: 1, -98.0: 1, -38.0: 1, -8.0: 1, -11.0: 1, -14.0: 1, -18.0: 1, -9.0: 1, -10.0: 1, -43.0: 1, -49.0: 1, -6.0: 1})\n\nColumn e:\nCounter({4.1: 1285, 3.4: 912, 3.3: 905, 4.0: 884, 4.2: 812, 3.5: 797, 3.6: 713, 3.7: 708, 3.2: 666, 3.9: 640, 3.8: 628, 4.3: 512, 4.4: 359, 2.1: 351, 4.5: 294, 3.1: 276, 2.2: 269, 4.6: 216, 2.3: 185, 4.7: 175, 2.4: 145, 4.8: 142, 4.9: 135, 5.0: 130, 5.1: 90, 2.5: 88, 5.2: 72, 2.6: 66, 2.8: 64, 2.7: 64, 5.3: 58, 3.0: 54, 2.9: 50, 2.0: 38, 5.4: 34, 5.5: 28, 6.3: 22, 6.6: 21, 5.7: 16, 6.2: 16, 5.6: 16, 5.8: 15, 6.7: 14, 6.8: 12, 6.1: 12, 6.5: 9, 5.9: 8, 6.4: 6, 6.0: 4, 7.2: 4, 6.9: 3, 7.0: 1, 7.5: 1, 7.1: 1})\n\nColumn f:\nCounter({0.7: 1475, 0.6: 1472, 0.8: 1444, 1.0: 1385, 0.9: 1335, 0.5: 1249, 0.4: 1014, 1.1: 974, 0.3: 708, 0.0: 482, 0.2: 423, 0.1: 294, 1.2: 241, 1.3: 119, 1.4: 81, 1.5: 56, 1.6: 37, 1.8: 33, 1.9: 25, -0.1: 23, 1.7: 22, -1.1: 19, 2.3: 15, 2.4: 12, 2.1: 9, -1.3: 9, -0.6: 8, -0.9: 8, -0.7: 7, 2.0: 7, -0.8: 5, -1.9: 5, -1.2: 4, 2.2: 4, -0.2: 4, 2.8: 3, 2.6: 2, 2.5: 2, -0.3: 2, -0.5: 2, 5.1: 1, -1.0: 1, 2.7: 1, 3.0: 1, -1.8: 1, -1.6: 1, -4.5: 1})\n\nColumn label:\nCounter({0.0: 11000, 1.0: 2026})\n\n\n\n\n# define categorical and continuous features\ncat_names = ['a', 'b']\ny_names = 'label'\ncont_names = [c for c in df.keys() if c not in cat_names+[y_names]]\n\n\nprint('cat_names:',cat_names)\nprint('cont_names:',cont_names)\nprint('y_names:',y_names)\n\ncat_names: ['a', 'b']\ncont_names: ['c', 'd', 'e', 'f']\ny_names: label\n\n\n\n# split into train and test\nval_index = list(df.sample(frac=0.2, random_state=0).index) # 20% from total df\ntrain_index = list(df[~df.index.isin(val_index)].index)\n\nassert (len([i for i in train_index if i in set(val_index)])==0 \n        and len([i for i in val_index if i in set(train_index)])==0), 'train and val set are overlapping!'\n\nprint('train set len', len(train_index))\nprint('val set len', len(val_index))\n\ntrain set len 10421\nval set len 2605\n\n\n\nError Example\n\n# oh no, can't train!\n\ndl = TabularPandas(df, \n                   cat_names=cat_names, \n                   cont_names=cont_names, \n                   y_names=y_names,\n                   y_block = CategoryBlock(vocab=df[y_names]), \n                   splits=(train_index, val_index))\n\ndls = dl.dataloaders(bs=64)\nprint(dls.show_batch())\nlearn = tabular_learner(dls, metrics=[accuracy])\nlearn.fit_one_cycle(3)\n\n\n\n\n\na\nb\nc\nd\ne\nf\nlabel\n\n\n\n\n0\n1.0\n12.0\n7.0\n9.0\n3.9\n0.6\n0.0\n\n\n1\n2.0\n12.0\n3.0\n15.0\n4.1\n0.3\n0.0\n\n\n2\n2.0\n12.0\n4.0\n-1.0\n4.0\n0.7\n0.0\n\n\n3\n2.0\n12.0\n11.0\n15.0\n4.1\n1.4\n0.0\n\n\n4\n2.0\n12.0\n4.0\n12.0\n4.2\n0.6\n0.0\n\n\n5\n2.0\n32.0\n14.0\n6.0\n5.2\n0.2\n0.0\n\n\n6\n1.0\n12.0\n4.0\n9.0\n3.2\n0.3\n1.0\n\n\n7\n3.0\n32.0\n5.0\n15.0\n3.5\n0.7\n0.0\n\n\n8\n2.0\n12.0\n3.0\n14.0\n2.6\n0.5\n0.0\n\n\n9\n3.0\n12.0\n0.0\n-2.0\n4.1\n-0.0\n0.0\n\n\n\n\n\nNone\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[43], line 10\n      8 dls = dl.dataloaders(bs=64)\n      9 print(dls.show_batch())\n---&gt; 10 learn = tabular_learner(dls, metrics=[accuracy])\n     11 learn.fit_one_cycle(3)\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastai/tabular/learner.py:42, in tabular_learner(dls, layers, emb_szs, config, n_out, y_range, **kwargs)\n     40 if layers is None: layers = [200,100]\n     41 to = dls.train_ds\n---&gt; 42 emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)\n     43 if n_out is None: n_out = get_c(dls)\n     44 assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastai/tabular/model.py:32, in get_emb_sz(to, sz_dict)\n     27 def get_emb_sz(\n     28     to:Tabular|TabularPandas, \n     29     sz_dict:dict=None # Dictionary of {'class_name' : size, ...} to override default `emb_sz_rule` \n     30 ) -&gt; list: # List of embedding sizes for each category\n     31     \"Get embedding size for each cat_name in `Tabular` or `TabularPandas`, or populate embedding size manually using sz_dict\"\n---&gt; 32     return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastai/tabular/model.py:32, in &lt;listcomp&gt;(.0)\n     27 def get_emb_sz(\n     28     to:Tabular|TabularPandas, \n     29     sz_dict:dict=None # Dictionary of {'class_name' : size, ...} to override default `emb_sz_rule` \n     30 ) -&gt; list: # List of embedding sizes for each category\n     31     \"Get embedding size for each cat_name in `Tabular` or `TabularPandas`, or populate embedding size manually using sz_dict\"\n---&gt; 32     return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/basics.py:507, in GetAttr.__getattr__(self, k)\n    505 if self._component_attr_filter(k):\n    506     attr = getattr(self,self._default,None)\n--&gt; 507     if attr is not None: return getattr(attr,k)\n    508 raise AttributeError(k)\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/transform.py:212, in Pipeline.__getattr__(self, k)\n--&gt; 212 def __getattr__(self,k): return gather_attrs(self, k, 'fs')\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/transform.py:173, in gather_attrs(o, k, nm)\n    171 att = getattr(o,nm)\n    172 res = [t for t in att.attrgot(k) if t is not None]\n--&gt; 173 if not res: raise AttributeError(k)\n    174 return res[0] if len(res)==1 else L(res)\n\nAttributeError: classes\n\n\n\nHow to fix this?\nI actually went down the rabbit hole and provided the emb_szs manually as mentioned in the source code hinted by error message above, but there is actually an easier way – just add procs=[Categorify] when initializing TabularPandas.\n\nIn the source code, emb_szs is expected to be {'class_name' : size, ...}. So for example if column a is a categorical column in our df, then emb_szs = {'a': len(unique value in column 'a')}.\n\n\n\nWorking Example\n\n# now we can train\n\ndl = TabularPandas(df, \n                   cat_names=cat_names, \n                   cont_names=cont_names, \n                   y_names=y_names,\n                   y_block = CategoryBlock(vocab=df[y_names]), \n                   splits=(train_index, val_index),\n                   procs=[Categorify])  # &lt;------ add procs!\n\ndls = dl.dataloaders(bs=64)\nprint(dls.show_batch())\nlearn = tabular_learner(dls, metrics=[accuracy])\nlearn.fit_one_cycle(3)\n\n\n\n\n\na\nb\nc\nd\ne\nf\nlabel\n\n\n\n\n0\n2.0\n32.0\n15.0\n15.0\n3.6\n0.8\n0.0\n\n\n1\n3.0\n32.0\n9.0\n15.0\n4.5\n0.7\n0.0\n\n\n2\n2.0\n32.0\n9.0\n14.0\n3.9\n0.5\n1.0\n\n\n3\n2.0\n12.0\n6.0\n-1.0\n4.0\n1.0\n0.0\n\n\n4\n2.0\n12.0\n8.0\n15.0\n3.7\n0.9\n0.0\n\n\n5\n2.0\n12.0\n4.0\n15.0\n3.7\n0.7\n1.0\n\n\n6\n1.0\n12.0\n0.0\n15.0\n4.0\n0.7\n0.0\n\n\n7\n3.0\n12.0\n0.0\n15.0\n3.3\n0.5\n0.0\n\n\n8\n2.0\n12.0\n5.0\n15.0\n4.3\n0.9\n0.0\n\n\n9\n2.0\n12.0\n9.0\n15.0\n4.3\n0.9\n0.0\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.482110\n0.418015\n0.832246\n00:09\n\n\n1\n0.349364\n0.333562\n0.852591\n00:07\n\n\n2\n0.322106\n0.323014\n0.854511\n00:07\n\n\n\n\n\n\n\n\nWhy did we get this error?\n\nget_emb_sz??\n\n\nSignature: get_emb_sz(to: 'Tabular | TabularPandas', sz_dict: 'dict' = None) -&gt; 'list'\nSource:   \ndef get_emb_sz(\n    to:Tabular|TabularPandas, \n    sz_dict:dict=None # Dictionary of {'class_name' : size, ...} to override default `emb_sz_rule` \n) -&gt; list: # List of embedding sizes for each category\n    \"Get embedding size for each cat_name in `Tabular` or `TabularPandas`, or populate embedding size manually using sz_dict\"\n    return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\nFile:      /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastai/tabular/model.py\nType:      function\n\n\n\n\nfrom fastai.tabular.model import _one_emb_sz\n_one_emb_sz??\n\n\nSignature: _one_emb_sz(classes, n, sz_dict=None)\nSource:   \ndef _one_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat,sz\nFile:      /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastai/tabular/model.py\nType:      function\n\n\n\nWe see that the error is due to get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs) line. The get_emb_sz function tries to return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]. We get error because our dataloaders has no classes attributes .\nHere, classes attributes is what category do we have in each of our categorical columns. In simple_df below, we would declare aa column as categorical feature, with 3 separate classes [1, 2, 3]. The learner doesn’t know this because we did not specify to Categorify our categorical column when initializing our dataloaders.\n\nsimple_df = pd.DataFrame({'aa': [1, 2, 3, 1], 'bb':[1.1, 2.2, 3.3, 5.0], 'label':[1, 0, 1, 1]})\nsimple_df\n\n\n\n\n\n\n\n\naa\nbb\nlabel\n\n\n\n\n0\n1\n1.1\n1\n\n\n1\n2\n2.2\n0\n\n\n2\n3\n3.3\n1\n\n\n3\n1\n5.0\n1\n\n\n\n\n\n\n\n\n# no classes attributes\n\nTabularPandas(simple_df, \n              cat_names = ['aa'], \n              cont_names = ['bb'],\n              y_names = ['label'],\n              y_block = CategoryBlock(vocab=simple_df[y_names]), \n              splits = ([0,1,2], [3]),\n             ).dataloaders(bs=64).classes\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[32], line 7\n      1 TabularPandas(simple_df, \n      2               cat_names = ['aa'], \n      3               cont_names = ['bb'],\n      4               y_names = ['label'],\n      5               y_block = CategoryBlock(vocab=simple_df[y_names]), \n      6               splits = ([0,1,2], [3]),\n----&gt; 7              ).dataloaders(bs=64).classes\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/basics.py:507, in GetAttr.__getattr__(self, k)\n    505 if self._component_attr_filter(k):\n    506     attr = getattr(self,self._default,None)\n--&gt; 507     if attr is not None: return getattr(attr,k)\n    508 raise AttributeError(k)\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/basics.py:507, in GetAttr.__getattr__(self, k)\n    505 if self._component_attr_filter(k):\n    506     attr = getattr(self,self._default,None)\n--&gt; 507     if attr is not None: return getattr(attr,k)\n    508 raise AttributeError(k)\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/basics.py:507, in GetAttr.__getattr__(self, k)\n    505 if self._component_attr_filter(k):\n    506     attr = getattr(self,self._default,None)\n--&gt; 507     if attr is not None: return getattr(attr,k)\n    508 raise AttributeError(k)\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/transform.py:212, in Pipeline.__getattr__(self, k)\n--&gt; 212 def __getattr__(self,k): return gather_attrs(self, k, 'fs')\n\nFile /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.11/site-packages/fastcore/transform.py:173, in gather_attrs(o, k, nm)\n    171 att = getattr(o,nm)\n    172 res = [t for t in att.attrgot(k) if t is not None]\n--&gt; 173 if not res: raise AttributeError(k)\n    174 return res[0] if len(res)==1 else L(res)\n\nAttributeError: classes\n\n\n\n\n# now we have classes attributes\n\nTabularPandas(simple_df, \n              cat_names = ['aa'], \n              cont_names = ['bb'],\n              y_names = ['label'],\n              y_block = CategoryBlock(vocab=simple_df[y_names]), \n              splits = ([0,1,2], [3]),\n              procs = [Categorify]\n             ).dataloaders(bs=64).classes\n\n{'aa': ['#na#', 1, 2, 3]}\n\n\nThat’s all for now, bye!"
  },
  {
    "objectID": "til.html",
    "href": "til.html",
    "title": "Today I learn",
    "section": "",
    "text": "Postgresql JOIN USING vs JOIN ON 🥞\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nClear docker cache\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Save & Load FastAI Model\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nIncompleteRead When Downloading From 🪣 AWS S3\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nCreating DataBlock from Numpy Array\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nFastai Lesson0 Key Insights\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2024\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nHow to build 🐳 Docker Image & run Container\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nTabularPandas AttributeError: classes\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nConda ImportError when trying to run python file\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nConda ValueError when trying to open jupyter notebook\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "til/200624_incompleteread.html",
    "href": "til/200624_incompleteread.html",
    "title": "IncompleteRead When Downloading From 🪣 AWS S3",
    "section": "",
    "text": "Set keep alive connection to avoid IncompleteRead that is due to connection error\n\n\n\n\nimage.png\n\n\nMy challenge today was figuring out why my code could not run. I got IncompleteRead error when trying to load data from AWS S3. The file is only 400 MB. I tried multiple solutions from github issues to stackoverflow answers. The only workaround that worked for me was setting these in terminal:\n\nsudo sysctl net.inet.tcp.keepintvl=200000\nsudo sysctl net.inet.tcp.keepidle=200000\nsudo sysctl net.inet.tcp.keepinit=200000\nsudo sysctl net.inet.tcp.always_keepalive=1\n\nAnd run again, and again. Now, my code doesn’t exit out anymore and I still don’t know why 😅\nSome useful references: 1. https://docs.aws.amazon.com/redshift/latest/mgmt/connecting-firewall-guidance.html 2. https://github.com/boto/boto3/issues/2424"
  },
  {
    "objectID": "til/140524_conda_ImportError.html",
    "href": "til/140524_conda_ImportError.html",
    "title": "Conda ImportError when trying to run python file",
    "section": "",
    "text": "Update typing_extensions when getting ImportError\n\nTraceback (most recent call last):\n...\nfrom typing_extensions import TypeAlias # Python 3.10+ ImportError: cannot import name 'TypeAlias' from 'typing_extensions' (/opt/homebrew/Caskroom/miniforge/base/envs/my_env/lib/python3.10/site-packages/typing_extensions.py)\n\nSteps to reproduce error\n\nOpen terminal\nCreate requirements.txt in current working directory\n\n# requirements.txt\ntyping-extensions ==3.7.4\n\nCreate new environment with python=3.10, install pip, install required libraries from requirements.txt using pip. Here, our environment is called my_env.\n\nconda create -n myenv python=3.10\nconda install pip\npip install -r requirements.txt\n\nCreate a dummy python file called run.py in current working directory\n\n# run.py\nprint('hello world!')\n\nRun run.py from terminal\n\npython run.py\n\n\nHow to fix it\nUpgrade typing_extensions by:\npip install typing_extensions==4.7.1 --upgrade"
  },
  {
    "objectID": "til/130524_conda_ValueError.html",
    "href": "til/130524_conda_ValueError.html",
    "title": "Conda ValueError when trying to open jupyter notebook",
    "section": "",
    "text": "Getting ValueError when forgetting to add conda when trying to activate conda environment\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Caskroom/miniforge/base/bin/jupyter-notebook\", line 10, in &lt;module&gt;\n    sys.exit(main())\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/jupyter_core/application.py\", line 283, in launch_instance\n    super().launch_instance(argv=argv, **kwargs)\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n    app.initialize(argv)\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/traitlets/config/application.py\", line 118, in inner\n    return method(app, *args, **kwargs)\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/notebook/notebookapp.py\", line 2171, in initialize\n    self.init_webapp()\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/notebook/notebookapp.py\", line 1779, in init_webapp\n    self.web_app = NotebookWebApplication(\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/notebook/notebookapp.py\", line 178, in __init__\n    settings = self.init_settings(\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/notebook/notebookapp.py\", line 316, in init_settings\n    nbextensions_path=jupyter_app.nbextensions_path,\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/notebook/notebookapp.py\", line 1349, in nbextensions_path\n    from IPython.paths import get_ipython_dir\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/IPython/__init__.py\", line 55, in &lt;module&gt;\n    from .terminal.embed import embed\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/IPython/terminal/embed.py\", line 16, in &lt;module&gt;\n    from IPython.terminal.interactiveshell import TerminalInteractiveShell\n  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/IPython/terminal/interactiveshell.py\", line 31, in &lt;module&gt;\n    from prompt_toolkit.auto_suggest import AutoSuggestFromHistory\nValueError: source code string cannot contain null bytes\n\nSteps to reproduce error\n\nOpen terminal\nActivate your environment, here myenv:\n\n(base) activate myenv\n\nOpen jupyter notebook\n\njupyter notebook\n\n\nHow to fix it\nThe error is because I did not specify conda when trying to activate environment. It should be:\n(base) conda activate myenv\n\n\nWhy we get this error\nWhen we do activate myenv, we are still in our base environment and not myenv. Perhaps some of the libraries required to open jupyter notebook is outdated in our base environment."
  },
  {
    "objectID": "til/190624_lesson0.html",
    "href": "til/190624_lesson0.html",
    "title": "Fastai Lesson0 Key Insights",
    "section": "",
    "text": "Notes I made while listening to Fastai Lesson0\n\n\nFinish the course.\n\n“Tenacity” is a choice\n“Tenacity” is not about ignoring the bumps but it is keeping going after the bumps\n\nRadek’s book Meta Learning: How to Learn Deep Learning And Thrive In The Digital World:\n\n4-legged table that will help you do your deep learning experiments more effectively and efficiently:\n\nCode concepts: knowing the basic ideas around the code\nEditor: knowing your tools\ngit & github: knowing how to save your work, how to pull people’s work\nssh/ Linux: knowing how to access a server and do stuff with it\n\n\nThere’s nothing to be ashamed of if you’ve never used git or ssh or whatever, they are just tools that most people have to figure out in the journey.\nRecommended MOOC to get started on programming:\n\nHarvard CS50\nThe Missing Semester of Your CS Education\n\nFocus on making 1 project great and polishing it off and finishing it.\n\nThe project doesn’t have to be a pioneer\n\nWrite a blog.\n\nGood place to start: write down a talk/video that you like. Doing this helps the person giving the talk reaching people using a second medium, and help others learning about the talk in writings (a lot of poeple prefer reading than listening).\n\nCreate a good validation set.\n\nBlog post by Rachel Thomas\n\nAlways start with a simple baseline.\n\nA baseline: the simplest model you can that you know can solve the problem so simply that you can’t make any mistakes. Below are some example baselines:\n\nTaking the average of your data as the ypred for each ‘group’\n\nIn deep learning, it is much harder to see that you are wrong, often it is just going to be half percent less accurate etc. For example, it could be that you unknowingly fed in images are upside down, and trained a model that can only recognize upside down images.\n\nSuccessful machine learning projects:\n\nCreate the simplest possible solution that gets something all the way from end-to-end.\nGradually making it slightly better.\n\nDo Kaggle competition as your project.\n\nMindset: To do your best, instead of trying to win on your first competition.\n\nImportant ingredients on finding a job:\n\nPortfolio: blog posts, github projects, community engagement"
  },
  {
    "objectID": "til/190624_howtodocker.html",
    "href": "til/190624_howtodocker.html",
    "title": "How to build 🐳 Docker Image & run Container",
    "section": "",
    "text": "Step by step guide on how to build docker image on VSCode and run docker container on Docker Desktop App\n\nIt is seldom that I needed to use docker to validate pre-production code, but when I do, I find myself always having to retrace my steps trying to learn how to use docker again. So here is step by step guide to remind myself:\n\n1. Build docker image\n\nOpen VSCode window, choose “Open Folder”.\nChoose the directory where we store the pre-production code we want to test. Eg “myfolder” here.\n\n\n.\n└── myfolder/\n    ├── newmodel_prediction.py\n    ├── requirements.txt\n    ├── Dockerfile\n    ├── .gitignore\n    └── .dockerignore\n\n\nIf not already exist, add .dockerignore. If the file we want to ignore is not in ‘./myfolder’ directory, we need to include full filepath.\n\n\n# .dockerignore\nDockerfile\nbin\ninclude\nlib\nvenv\n.env\n\n\nIf not already exist, create .gitignore. Fill in any filenames that you want to exclude. If the file we want to ignore is not in ‘./myfolder’ directory, we need to include full filepath.\n\n\n# .gitignore\n.env\nbin\nlib\ninclude\nshare\n.ipynb_checkpoints\n\n\nIf not already exist, create requirements.txt. We can automatically create one using terminal. In terminal:\n\n\n# make sure we have pipreqs installed, if not install using:\n!pip install pipreqs\n\n# create requirements.txt in the parent directory\n!pipreqs .\n\n\nCreate Dockerfile. Currently, below is the minimal working dockerfile we can use to test any pre-production code. The last line CMD [\"python3.8\", \"./newmodel_prediction.py\"] means as soon as the container is running, run python 3.8 ./newmodel_prediction.py.\n\n\n# Dockerfile\n\n# enter what specific python image we want to work with\nFROM python:3.8.16\n\nRUN apt-get install libgomp1\n\nWORKDIR /usr/local/bin\nADD . ./\n\nRUN python -m pip install -r requirements.txt\n\n# what command we want to run as soon as the container is running\nCMD [\"python3.8\", \"./newmodel_prediction.py\"]\n\n\nOpen up docker desktop apps.\nBuild docker image. The easiest way to create an image in VSCode:\n\nOpen up Dockerfile\nIn Dockerfile, right-click and select “Build Image…” \nLook notice the “myfolder:1” in the command pallete. “myfolder” is there because it is the name of our current directory, this will become the default image name. “1” here is the default image tag. We can change both the image name and the tag if we wish, or just press enter to use the default. \nIf there is no error, your terminal should look similar like so. \nObserve that we have newly created image in our docker desktop app. \n\n\n\n\n2. Create docker container & run\n\nClick on the newly created image. \nSet container name (optional). Add any environment variables if needed. The environment variables you included here will be used to run the container. (See docker documentation for environment variables precedence) \nYou will be directed to container tab. Notice the container name “testrun1”, image name and tag “myfolder:1”.You can confirm that the container is currently running when the play button ▶️ on the right hand corner is grayed out. You can stop the container by clicking on the stop button ⏹. Since we created our ended our Dockerfile with CMD [\"python3.8\", \"./newmodel_prediction.py\"], this means it will directly run the specified file. However, we could also manually run anything through the terminal should we wish, like so. \n\nNote: Docker containers and images take up space. You might want to delete them if unused."
  },
  {
    "objectID": "blog/smithwaterman_py.html",
    "href": "blog/smithwaterman_py.html",
    "title": "Smith-Waterman Local Alignment using Python",
    "section": "",
    "text": "Smith-Waterman is a local alignment method for sequence alignment. Below is example implementation using python.\n\n\n\n\n\n\n\nNote\n\n\n\nThis post was written using: - biopython: 1.78\n\n\n\nfrom typing import Union, List\n\nfrom Bio import Align\n\n\n\ndef get_score(A:str, B:str, mismatch_penalty:int, match_score:int) -&gt; int:\n    # match\n    if A == B:\n        return match_score\n    \n    # mismatch\n    return mismatch_penalty\n\ndef init_matrix(A: str, B: str) -&gt; list:\n    lenA = len(A) + 1\n    lenB = len(B) + 1\n    matrix = []\n    for i in range(lenB):\n        matrix.append([0] * lenA)\n\n    return matrix\n\n\ndef noNeg(x:int) -&gt; int:\n    return max(0, x)\n\n\ndef SmithWaterman(A, B, gap_penalty:int=-2, mismatch_penalty:int=-1, match_score:int=4) -&gt; Union[list, int, list]:\n    \"\"\" initialize matrix and fill\n\n    Returns:\n        list: 2D array of filled value according to Smith-Waterman algorithm\n        int: Max value in the final filled `matrix`\n        list: List of position [row, col] of `max_score` in `matrix`\n\n    \"\"\"\n    matrix = init_matrix(A, B)\n\n    # in sw, lower bound to 0\n    for m in range(len(matrix)):\n        for n in range(len(matrix[0])):\n            matrix[m][n] = noNeg(matrix[m][n])\n\n    diag = [[-1, -1]]\n    top = [[-1, 0]]\n    left = [[0, -1]]\n\n    max_score = 0\n    max_score_position = []\n\n    for row in range(1, len(B)+1):\n        for col in range(1, len(A)+1):\n            a_char = A[col-1]\n            b_char = B[row-1]\n\n            for dr,dc in left:\n                l = matrix[row + dr][col + dc] + gap_penalty\n\n            for dr,dc in top:\n                t = matrix[row + dr][col + dc] + gap_penalty\n            \n            for dr,dc in diag:\n                d = matrix[row + dr][col + dc] + get_score(a_char, b_char, mismatch_penalty, match_score)\n\n            # l,t,d lower bouded to 0 (SW property)\n            cur_score = max(noNeg(l), noNeg(t), noNeg(d))\n            if cur_score &gt; max_score:\n                max_score = cur_score\n                max_score_position = [row, col]\n\n            matrix[row][col] = cur_score\n\n    return matrix, max_score, max_score_position\n\n\ndef traceback(matrix: list, A: str, B: str,\n              max_score_position: list, \n              gap_penalty: int,\n              mismatch_penalty: int,\n              match_score: int) -&gt; List[str]:\n    aligned_A = []\n    aligned_B = []\n\n    row = max_score_position[0]\n    col = max_score_position[1]\n\n    while row &gt; 0 and col &gt; 0:\n        d = matrix[row - 1][col - 1]\n        t = matrix[row - 1][col]\n        l = matrix[row][col - 1]\n\n        # Stop when we reach a score of 0 (SW property)\n        if matrix[row][col] == 0:\n            break\n\n        # Diagonal move (match/mismatch)\n        if matrix[row][col] == d + get_score(A[col-1], B[row-1], mismatch_penalty, match_score):\n            aligned_A.append(A[col-1])\n            aligned_B.append(B[row-1])\n            row -= 1\n            col -= 1\n        # Left move (gap in B)\n        elif matrix[row][col] == l + gap_penalty:\n            aligned_A.append(A[col-1])\n            aligned_B.append('-')\n            col -= 1\n        # Top move (gap in A)\n        elif matrix[row][col] == t + gap_penalty:\n            aligned_A.append('-')\n            aligned_B.append(B[row-1])\n            row -= 1\n\n    return ''.join(reversed(aligned_A)), ''.join(reversed(aligned_B))\n\n\n## Params\n\nGAP_PENALTY = -2\nMISMATCH_PENALTY = -1\nMATCH_SCORE = 2\n\n\n\n\nA, B = \"AACG\", \"AATCG\"  # A = top, B = left\nmatrix, max_score, max_score_position = SmithWaterman(A, B,\n                                                      gap_penalty = GAP_PENALTY, \n                                                      mismatch_penalty = MISMATCH_PENALTY,\n                                                      match_score = MATCH_SCORE)\nfor m in matrix:\n    print(m)\n\n[0, 0, 0, 0, 0]\n[0, 2, 2, 0, 0]\n[0, 2, 4, 2, 0]\n[0, 0, 2, 3, 1]\n[0, 0, 0, 4, 2]\n[0, 0, 0, 2, 6]\n\n\n\nmax_score\n\n6\n\n\n\nmax_score_position\n\n[5, 4]\n\n\n\n\n\nimage-3.png\n\n\nAbove is the filled in matrix. The highlighted cell is the max_score.\n\nTraceback\n\n\naligned_A, aligned_B = traceback(matrix, A, B,\n                                  max_score_position,\n                                  gap_penalty = GAP_PENALTY,\n                                  mismatch_penalty = MISMATCH_PENALTY,\n                                  match_score = MATCH_SCORE)\n\nprint(\"Alignment:\")\nprint(aligned_A)\nprint(aligned_B)\n\nAlignment:\nAA-CG\nAATCG\n\n\n\n\n\nimage.png\n\n\nWe get same output with University of Freiburg Smith-Waterman Tool (Ref 1).\n\n\nGet alignment score\n\naligner = Align.PairwiseAligner()\naligner.mode = 'local'\n\nalignments = aligner.align(aligned_A.replace('-',''), \n                           aligned_B.replace('-',''))\n\nfor alignment in sorted(alignments):\n    print(\"Score = %.1f:\" % alignment.score)\n    print(alignment)\n\nScore = 4.0:\nAA-CG\n||-||\nAATCG\n\n\n\n\n\nReferences\n\nUniversity of Freiburg Smith-Waterman Tool\nEMBL-EBI Emboss Water Tool\nBiopython Align\nJohn Lekberg’s Sequence Alignment Blogpost"
  },
  {
    "objectID": "blog/suffix_array.html",
    "href": "blog/suffix_array.html",
    "title": "Suffix Array",
    "section": "",
    "text": "db = \"GCATCGC\"\n\n\nSuffix Array\nOne motivation behind suffix array is that any position in our database that is a match to any substring of our query sequence can be thought of as the beginning of a suffix.\n\n\n\nimage.png\n\n\nTo illustrate: If we wanted to query the sequence C in database of GCATCGC then there would be 3 matching suffixes. 1. One suffix starts from the first C character at index 1. 2. The second suffix starts from the second C character at index 4. 3. The third suffix starts from the third C character at index 6.\nTo be able to do this, we first need to create an array of suffixes starting at each character of our database, then sort the array of suffixes alphabetically.\n\nsuffixes = {i:db[i:] for i,c in enumerate(db)}\nprint('Suffixes:\\t\\t', suffixes)\n\nSuffixes:        {0: 'GCATCGC', 1: 'CATCGC', 2: 'ATCGC', 3: 'TCGC', 4: 'CGC', 5: 'GC', 6: 'C'}\n\n\n\nsorted_suffixes = {k: v for k, v in sorted(suffixes.items(), key=lambda item: item[1])}\nsorted_suffix_keys = list(sorted_suffixes.keys())\nprint('Sorted Suffixes:\\t', sorted_suffixes)\nprint('Sorted Suffix Keys:\\t', sorted_suffix_keys)\n\nSorted Suffixes:     {2: 'ATCGC', 6: 'C', 1: 'CATCGC', 4: 'CGC', 5: 'GC', 0: 'GCATCGC', 3: 'TCGC'}\nSorted Suffix Keys:  [2, 6, 1, 4, 5, 0, 3]\n\n\n\n\nSuffix Array Search\nWe can do pattern matching on suffix array using binary search. Below we tried to search for suffixes matching the query GC.\n\nquery = 'GC'\nlow = 0\nhigh = len(suffixes) - 1\nfound = False\n\nwhile high &gt; low and not found:\n    mid = (low + high) // 2\n    \n    mid_key = sorted_suffix_keys[mid]\n    low_key = sorted_suffix_keys[low]\n    high_key = sorted_suffix_keys[high]\n\n    if query == suffixes[mid_key][:len(query)]:\n        found = True\n        while query not in suffixes[low_key][:len(query)] and suffixes[low_key][:len(query)] &lt; query and low &lt; mid:\n            low += 1\n        while query not in suffixes[high_key][:len(query)] and suffixes[high_key][:len(query)] &gt; query and high &gt; mid:\n            high -= 1\n        \n    elif suffixes[mid_key][:len(query)] &gt; query:\n        high = mid - 1\n        if high &lt; 0:\n            print('out of bound, not found')\n    elif suffixes[mid_key][:len(query)] &lt; query:\n        low = mid + 1\n        if low &gt;= len(suffixes):\n            print('out of bound, not found')\n\nprint('-'*100)\nprint('Query:\\n', query)\nprint('Original database:\\n', db)\nprint('Sorted suffix array:\\n', sorted_suffixes, '\\n')\nif found:\n    low_key = sorted_suffix_keys[low]\n    high_key = sorted_suffix_keys[high]\n    print(f'Query \"{query}\" has a match at positions in the sorted suffix array:\\t[{low_key}: {high_key}]')\nelse:\n    print(f'No match found for query {query}.')\nprint('-'*100)\n\n----------------------------------------------------------------------------------------------------\nQuery:\n GC\nOriginal database:\n GCATCGC\nSorted suffix array:\n {2: 'ATCGC', 6: 'C', 1: 'CATCGC', 4: 'CGC', 5: 'GC', 0: 'GCATCGC', 3: 'TCGC'} \n\nQuery \"GC\" has a match at positions in the sorted suffix array: [5: 0]\n----------------------------------------------------------------------------------------------------\n\n\nLet’s make this as a function and do searching on some more queries.\n\ndef get_suffixes(db:str) -&gt; tuple:\n    \"\"\"Create suffix array and sort it in alphabetical order by the suffix sequences\"\"\"\n    suffixes = {i:db[i:] for i,c in enumerate(db)}\n    sorted_suffixes = {k: v for k, v in sorted(suffixes.items(), key=lambda item: item[1])}\n    return suffixes, sorted_suffixes\n\ndef query_suffix_array(query:str, db:str, verbose:bool=False) -&gt; list:\n    \"\"\"Search for query in the preprocessed suffix array using binary search.\n    Returns a list of matched suffix sequences.\n    \"\"\"\n\n    suffixes, sorted_suffixes = get_suffixes(db)\n    sorted_suffix_keys = list(sorted_suffixes.keys())\n    \n    low = 0\n    high = len(suffixes) - 1\n    found = False\n    \n    while high &gt; low and not found:\n        mid = (low + high) // 2\n        \n        mid_key = sorted_suffix_keys[mid]\n        low_key = sorted_suffix_keys[low]\n        high_key = sorted_suffix_keys[high]\n        if verbose: print('low key', low_key, 'mid key', mid_key, 'high key', high_key)\n    \n        if query == suffixes[mid_key] or query in suffixes[mid_key][:len(query)]:\n            found = True\n            while query not in suffixes[low_key][:len(query)] and suffixes[low_key] &lt; query and low &lt; mid:\n                low += 1\n                low_key = sorted_suffix_keys[low]\n                \n                if verbose: print('found bound, new low', sorted_suffix_keys[low])\n                if query == suffixes[low_key][:len(query)]:\n                    break\n            while query not in suffixes[high_key][:len(query)] and suffixes[high_key] &gt; query and high &gt; mid:\n                high -= 1\n                high_key = sorted_suffix_keys[high]\n                \n                if verbose: print('found bound, new high1', sorted_suffix_keys[high])\n                if query == suffixes[high_key][:len(query)]:\n                    break\n\n            while query in suffixes[sorted_suffix_keys[high+1]][:len(query)]:\n                high += 1\n                if verbose: print('found bound, new high2', sorted_suffix_keys[high])\n            \n        elif suffixes[mid_key] &gt; query:\n            high = mid\n            if verbose: print('move high=mid')\n            if high &lt; 0:\n                print('out of bound, not found')\n        elif suffixes[mid_key] &lt; query:\n            low = mid\n            if verbose: print('move low=mid')\n            if low &gt;= len(suffixes):\n                print('out of bound, not found')\n\n    print('-'*100)\n    print('Query:\\n', query)\n    print('Original database:\\n', db)\n    print('Sorted suffix array:\\n', sorted_suffixes, '\\n')\n    \n    if found:\n        low_key = sorted_suffix_keys[low]\n        high_key = sorted_suffix_keys[high]\n        result = [low_key, high_key]\n\n        start_result_index = sorted_suffix_keys.index(result[0])\n        end_result_index = sorted_suffix_keys.index(result[1])\n        result_keys = sorted_suffix_keys[start_result_index : end_result_index+1]\n        matched_result = [sorted_suffixes[k] for k in sorted_suffixes if k in result_keys]\n        \n        print('-'*100)\n        print(f'Query \"{query}\" has a match at positions in the sorted suffix array:\\t[{low_key}: {high_key}]')\n        print('Matched suffixes:\\t', matched_result)\n        print('-'*100)\n        return matched_result\n        \n    \n    print('-'*100)\n    print(f'No match found for query {query}.')\n    print('-'*100)\n    return []\n    \n    \n\n\nquery = \"ACC\"\nquery_suffix_array(query, db)\n\n----------------------------------------------------------------------------------------------------\nQuery:\n ACC\nOriginal database:\n GCATCGC\nSorted suffix array:\n {2: 'ATCGC', 6: 'C', 1: 'CATCGC', 4: 'CGC', 5: 'GC', 0: 'GCATCGC', 3: 'TCGC'} \n\n----------------------------------------------------------------------------------------------------\nNo match found for query ACC.\n----------------------------------------------------------------------------------------------------\n\n\n[]\n\n\n\nquery = \"C\"\nquery_suffix_array(query, db)\n\n----------------------------------------------------------------------------------------------------\nQuery:\n C\nOriginal database:\n GCATCGC\nSorted suffix array:\n {2: 'ATCGC', 6: 'C', 1: 'CATCGC', 4: 'CGC', 5: 'GC', 0: 'GCATCGC', 3: 'TCGC'} \n\n----------------------------------------------------------------------------------------------------\nQuery \"C\" has a match at positions in the sorted suffix array:  [6: 4]\nMatched suffixes:    ['C', 'CATCGC', 'CGC']\n----------------------------------------------------------------------------------------------------\n\n\n['C', 'CATCGC', 'CGC']\n\n\n\nquery = \"AT\"\nquery_suffix_array(query, db)\n\n----------------------------------------------------------------------------------------------------\nQuery:\n AT\nOriginal database:\n GCATCGC\nSorted suffix array:\n {2: 'ATCGC', 6: 'C', 1: 'CATCGC', 4: 'CGC', 5: 'GC', 0: 'GCATCGC', 3: 'TCGC'} \n\n----------------------------------------------------------------------------------------------------\nQuery \"AT\" has a match at positions in the sorted suffix array: [2: 2]\nMatched suffixes:    ['ATCGC']\n----------------------------------------------------------------------------------------------------\n\n\n['ATCGC']\n\n\nReferences & Credits: 1. Advance Data Structures: Suffix Arrays 1. Advance Data Structures: Suffix Array Search"
  },
  {
    "objectID": "blog/visualizing_arrays.html",
    "href": "blog/visualizing_arrays.html",
    "title": "Visualizing Arrays using Excel",
    "section": "",
    "text": "Visualizing simple operations across arrays\n\n\nimport numpy as np\nimport torch\nfrom torch import tensor\n\nIn deep learning world, we are always working with arrays and tensors. They are data structure in which we store data for our model to train on. Both are multi-dimensional data structure and have similar functionality, but tensors had more restrictions than arrays.\nTensor must:\n\nuse a single basic numerical type for all components in the array.\ncan not be jagged. It is always regularly shaped multi-dimensional rectangular structure.\n\nI always had trouble trying to understand what exactly happen when we perform operations on any data structure that has higher dimension than a list (dimension of 1).\nSo, let’s use Excel to visualize some basic operations on arrays (or tensors)! Say we have 2 tensors, a and b. Both of dimension of 3.\n\n\n\nimage-2.png\n\n\n\na = tensor([[[1,2,3,4],\n            [40,50,60,70],\n            [7,8,9,10]], \n           \n           [[11,12,13,14],\n           [140,150,160,170],\n           [17,18,19,20]]])\n\n\nb = tensor([[[1,1,1,1],\n            [2,2,2,2],\n            [3,3,3,3]],\n           \n           [[1,1,1,1],\n           [2,2,2,2],\n           [3,3,3,3]]])\n\nprint('a shape:\\t', a.shape)\nprint('b shape:\\t', b.shape)\n\na shape:     torch.Size([2, 3, 4])\nb shape:     torch.Size([2, 3, 4])\n\n\n\nElement wise operation\n\n\n\nimage-2.png\n\n\nIf we subtract tensor a - tensor b, we are doing elementwise operation because both tensors a and b are of the same shape.\n\na_b = a - b\nprint('a_b shape:\\t', a_b.shape)\na_b\n\na_b shape:   torch.Size([2, 3, 4])\n\n\ntensor([[[  0,   1,   2,   3],\n         [ 38,  48,  58,  68],\n         [  4,   5,   6,   7]],\n\n        [[ 10,  11,  12,  13],\n         [138, 148, 158, 168],\n         [ 14,  15,  16,  17]]])\n\n\n\n\nSum across tensor\n\n\n\nimage.png\n\n\nIf we sum across the whole tensor, we will get a scalar value (dimension 0). Scalar value is another name for a number.\n\nprint(a_b.sum().shape)\na_b.sum()\n\ntorch.Size([])\n\n\ntensor(960)\n\n\n\n\nSum across axis\nNow, let’s do sum operation across axis. Axis could be sample, row or column. Notice that our tensor a_b had shape of (2,3,4). This means it is made up of 2 samples (E23:H25 cells is a sample, E27:H29 cells is the other sample), each sample has 3 rows and 4 columns. So from shape information, we know (total samples, total rows in each sample, total columns in each sample).\nIn code, the shape information is often represented as tuple data structure. Which means we can also do negative indexing, ie: - shape at index -2 == column information - shape at index -1 == row information - shape at index 0 == sample information\nSum across any axis would collapse the specified axis. What do I mean by this?\nOriginally, our a_b tensor is of shape (2, 3, 4). If we add all rows, keeping everything else the same. Our resulting shape would be (2, 3, 4) –&gt; (2, 1, 4)\n\n\n\nimage.png\n\n\n\nprint(a_b.sum(-2, keepdim=True).shape)\na_b.sum(-2, keepdim=True)\n\ntorch.Size([2, 1, 4])\n\n\ntensor([[[ 42,  54,  66,  78]],\n\n        [[162, 174, 186, 198]]])\n\n\nYup, this below is the same. The only difference here is that we use index here. Above, we use negative indexing style. The same thing, just different way of writing, don’t let it confuse you.\n\n\nprint(a_b.sum(1, keepdim=True).shape)\na_b.sum(1, keepdim=True)\n\ntorch.Size([2, 1, 4])\n\n\ntensor([[[ 42,  54,  66,  78]],\n\n        [[162, 174, 186, 198]]])\n\n\n\n\n\nimage.png\n\n\nSimilarly, if we add all columns, keeping everything the same. Then our resulting shape would be (2, 3, 4) –&gt; (2, 3, 1)\n\nprint(a_b.sum(-1, keepdim=True).shape)\na_b.sum(-1, keepdim=True)\n\ntorch.Size([2, 3, 1])\n\n\ntensor([[[  6],\n         [212],\n         [ 22]],\n\n        [[ 46],\n         [612],\n         [ 62]]])\n\n\n\nprint(a_b.sum(2, keepdim=True).shape)\na_b.sum(2, keepdim=True)\n\ntorch.Size([2, 3, 1])\n\n\ntensor([[[  6],\n         [212],\n         [ 22]],\n\n        [[ 46],\n         [612],\n         [ 62]]])\n\n\n\n\n\nimage.png\n\n\nNow, if we add all samples, keeping everything else the same. Our result would be from shape (2, 3, 4) –&gt; (1, 3, 4).\n\nprint(a_b.sum(0, keepdim=True).shape)\na_b.sum(0, keepdim=True)\n\ntorch.Size([1, 3, 4])\n\n\ntensor([[[ 10,  12,  14,  16],\n         [176, 196, 216, 236],\n         [ 18,  20,  22,  24]]])\n\n\n\nprint(a_b.sum(-3, keepdim=True).shape)\na_b.sum(-3, keepdim=True)\n\ntorch.Size([1, 3, 4])\n\n\ntensor([[[ 10,  12,  14,  16],\n         [176, 196, 216, 236],\n         [ 18,  20,  22,  24]]])\n\n\n\n\nSum across multiple axis\n\n\n\nimage.png\n\n\nWe can also do sum across multiple axis. Remember that our original tensor is of shape (2, 3, 4), if we do sum operation across both rows and columns, then we would be collapsing both of these axis, keeping everything else the same. So the resulting tensor would be from shape (2, 3, 4) –&gt; (2, 1, 1).\n\nprint(a_b.sum((-1,-2), keepdim=True).shape)\na_b.sum((-1,-2), keepdim=True)\n\ntorch.Size([2, 1, 1])\n\n\ntensor([[[240]],\n\n        [[720]]])\n\n\nAlso notice that the order in which we specify the axes does not matter. .sum((-1, -2)) is the same as .sum((-2, -1)).\n\nprint(a_b.sum((-2,-1), keepdim=True).shape)\na_b.sum((-2,-1), keepdim=True)\n\ntorch.Size([2, 1, 1])\n\n\ntensor([[[240]],\n\n        [[720]]])\n\n\n\n\n\nimage.png\n\n\nNow we sum all samples and rows, keeping everything else the same. The resulting tensor would be from (2, 3, 4) –&gt; (1, 1, 4).\n\nprint(a_b.sum((0,1), keepdim=True).shape)\na_b.sum((0,1), keepdim=True)\n\ntorch.Size([1, 1, 4])\n\n\ntensor([[[204, 228, 252, 276]]])\n\n\n\n\n\nimage.png\n\n\nLastly, if we sum all samples and columns, then the resulting tensor would be from (2, 3, 4) –&gt; (1, 3, 1).\nNotice that for resulting value 52, our excel formula is E23:H23 + E27:H27 ≈ we add everything from first row in sample 1, plus everything from first row in sample 2.\n\nprint(a_b.sum((0,-1), keepdim=True).shape)\na_b.sum((0,-1), keepdim=True)\n\ntorch.Size([1, 3, 1])\n\n\ntensor([[[ 52],\n         [824],\n         [ 84]]])\n\n\nHopefully, now it is easy to notice that any axis we choose to perform operations on would be collapsed to 1. Which means, when we collapsed all axes, it is equivalent to sum across everything in the tensor. ie in code, this is:\n\nprint(a_b.sum((0,1,2)).shape)\na_b.sum((0,1,2))\n\ntorch.Size([])\n\n\ntensor(960)\n\n\nwhich is the same as:\n\nprint(a_b.sum().shape)\na_b.sum()\n\ntorch.Size([])\n\n\ntensor(960)\n\n\nAll above operations can be also performed using numpy arrays. For example, the equivalent summing across samples and rows in numpy is:\n\nprint(np.array(a_b).sum((0,-1), keepdims=True).shape)\nnp.array(a_b).sum((0,-1), keepdims=True)\n\n(1, 3, 1)\n\n\narray([[[ 52],\n        [824],\n        [ 84]]])\n\n\nVisualizing these tensors and formulas on excel makes it easier to for me to see what happen in the background. Hopefully, it is helpful to you too."
  },
  {
    "objectID": "blog/get_data_geo2r.html",
    "href": "blog/get_data_geo2r.html",
    "title": "Extract data from GEO2R",
    "section": "",
    "text": "Gene Expression Omnibus (GEO) is a place where we can get publicly available datasets on gene expressions uploaded by the scientific community, for free. Here’s how we can extract data from the platform.\n\n1. Visit https://www.ncbi.nlm.nih.gov/geo/\n\n\n\nimage.png\n\n\n\n\n2. Search for keyword(s) of interest\nSearch for keyword(s) in search bar [1] and click on the search result for GEO DataSets Database [2].\n\n\n\nimage.png\n\n\n\n\n3. Filter search results\nChoose DataSets entry [3]. Select organisms you wish to investigate [4].\n\n\n\nimage.png\n\n\n\n\n4. Choose dataset(s) to investigate\nClick on the Series hyperlink on the choosen dataset we wish to proeceed with.\n\n\n\nimage.png\n\n\n\n\n5. Click on Analyze with GEO2R\n\n\n\nimage.png\n\n\n\n\n6. Split samples into Control & Treatment group\nTo create a new group, click Define groups and define the name of the group. Once group has been defined, select row(s) from the table to add to the group. Hold down shift to select multiple rows at once.\nOnce rows has been added to groups, you will see the group name under Group column instead of -.\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nAfter splitting into 2 (or more groups, if needed), your table should be similar to this:\n\n\n\nimage.png\n\n\n\n\n7. Analyze sample data using GEO2R tool\nClick on Analyze to check out the samples data. You can download the full table in tsv file by clicking the Download full table below.\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\nReferences & Credits: 1. Andrew Gao’s Udemy Course: Gene Expression 2. NCBI Tutorials 3. NCBI GEO Overview 4. Saint Louis University: GEO Tutorial"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Hi and welcome to my site!\nI’m Siti Sarah Amirah, a data scientist passionate about automating processes. I am currently focusing on ML use-cases to automate subscription services within my organization. Previously, I worked as a fraud investigation analyst within the e-commerce sector. I’m dedicated to continual learning and self-improvement."
  }
]